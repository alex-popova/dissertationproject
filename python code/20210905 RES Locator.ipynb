{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as nc\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from netCDF4 import Dataset as netcdf_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import time\n",
    "import geopandas \n",
    "import dask.dataframe as dd\n",
    "from math import radians, sin, cos, asin, sqrt\n",
    "from shapely.geometry import Polygon\n",
    "from shapely.geometry import Point\n",
    "import scipy.spatial as spatial\n",
    "from shapely import wkt\n",
    "import shapely\n",
    "import pyproj\n",
    "pyproj.datadir.set_data_dir(\"/opt/anaconda3/envs/geo_env/share/proj\")\n",
    "import numpy_financial as npf\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from numpy import savetxt\n",
    "from numpy import loadtxt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and prepare wind speed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read NASA datafile\n",
    "ds=xr.open_mfdataset('/Users/alexandrapopova/MERRA-2-2019/*.nc', parallel=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to dataframe\n",
    "source_df= ds.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reset names and indices \n",
    "source_df=source_df.rename(columns={\"SPEED\": \"Wind_Speed\"})\n",
    "source_df=source_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split datetime into date and time to aggregate next\n",
    "source_df['newdate']=source_df['time'].dt.date\n",
    "source_df['newtime']=source_df['time'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mark seasons\n",
    "def get_season (date):\n",
    "    month=date.month\n",
    "    if month<3 or month>8:\n",
    "        season=\"aw\"\n",
    "    else:\n",
    "        season=\"ss\"\n",
    "    return season\n",
    "source_df['season']=source_df['newdate'].apply(lambda x: get_season(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate\n",
    "aggr_df=source_df.groupby(['lat','lon','newtime','season'] ).agg({'Wind_Speed': ['mean', 'max', np.std, 'count']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df=aggr_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "z=1.645 # 90% confidence interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate intervals\n",
    "aggr_df['Wind_Speed_Min']=aggr_df['Wind_Speed']['mean']-z*aggr_df['Wind_Speed']['std']/np.sqrt(aggr_df['Wind_Speed']['count'])\n",
    "\n",
    "aggr_df['Wind_Speed_Max']=aggr_df['Wind_Speed']['mean']+z*aggr_df['Wind_Speed']['std']/np.sqrt(aggr_df['Wind_Speed']['count'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/geo_env/lib/python3.8/site-packages/pandas/core/generic.py:4153: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.\n",
      "  obj = obj._drop_axis(labels, axis, level=level, errors=errors)\n"
     ]
    }
   ],
   "source": [
    "aggr_df=aggr_df.drop(columns='Wind_Speed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df=aggr_df.rename(columns={\"newtime\": \"time\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df.columns = aggr_df.columns.droplevel(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df.to_csv('Wind_Speed_Dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggr_df=pd.read_csv('Wind_Speed_Dataframe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#increase the resolution x4\n",
    "half_lat=0.5*0.5\n",
    "half_lon=0.625*0.5\n",
    "\n",
    "aggr_df['coords']=list(zip(aggr_df['lon'],aggr_df['lat']))\n",
    "aggr_df_new_rows_1=aggr_df.copy()\n",
    "aggr_df_new_rows_2=aggr_df.copy()\n",
    "aggr_df_new_rows_3=aggr_df.copy()\n",
    "\n",
    "aggr_df['geometry']=aggr_df['coords'].apply(lambda x: Polygon([(x[0], x[1]), (x[0]-half_lon, x[1]), (x[0]-half_lon, x[1]+half_lat), (x[0], x[1]+half_lat)]))\n",
    "aggr_df_new_rows_1['geometry']=aggr_df_new_rows_1['coords'].apply(lambda x: Polygon([(x[0], x[1]), (x[0], x[1]+half_lat), (x[0]+half_lon, x[1]+half_lat), (x[0]+half_lon, x[1])]))\n",
    "aggr_df_new_rows_2['geometry']=aggr_df_new_rows_2['coords'].apply(lambda x: Polygon([(x[0], x[1]), (x[0]+half_lon, x[1]), (x[0]+half_lon, x[1]-half_lat), (x[0], x[1]-half_lat)]))\n",
    "aggr_df_new_rows_3['geometry']=aggr_df_new_rows_3['coords'].apply(lambda x: Polygon([(x[0], x[1]), (x[0], x[1]-half_lat), (x[0]-half_lon, x[1]-half_lat), (x[0]-half_lon, x[1])]))\n",
    "\n",
    "aggr_df=aggr_df.append(aggr_df_new_rows_1).append(aggr_df_new_rows_2).append(aggr_df_new_rows_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate turbine energy production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vestas_Power(x):\n",
    "    if x < 3:\n",
    "        return 0\n",
    "    else:\n",
    "        if (x>=3) and (x<4):\n",
    "            return (149*x-412) #source - power curves\n",
    "        else:\n",
    "            if (x>=4) and (x<12):\n",
    "                return (463.2*x-1755.5) #source - power curves\n",
    "            else: \n",
    "                if (x>=12) and (x<=22):\n",
    "                    return 3450 #source - power curves\n",
    "                else:\n",
    "                    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nordex_Power(x):\n",
    "    if x < 3:\n",
    "        return 0\n",
    "    else:\n",
    "        if (x>=3) and (x<5):\n",
    "            return (83*x-248) #source - power curves\n",
    "        else:\n",
    "            if (x>=5) and (x<14):\n",
    "                return (281.3*x-1126.9) #source - power curves\n",
    "            else: \n",
    "                if (x>=14) and (x<=25):\n",
    "                    return 2500 #source - power curves\n",
    "                else:\n",
    "                    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Enercon_Power(x):\n",
    "    if x < 3:\n",
    "        return 0\n",
    "    else:\n",
    "        if (x>=3) and (x<5):\n",
    "            return (27.5*x-80) #source - power curves\n",
    "        else:\n",
    "            if (x>=5) and (x<14):\n",
    "                return (88.8*x-363.04) #source - power curves\n",
    "            else: \n",
    "                if (x>=14) and (x<=34):\n",
    "                    return 810 #source - power curves\n",
    "                else:\n",
    "                    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df['Vestas_Power_Min']=aggr_df['Wind_Speed_Min'].apply(Vestas_Power)\n",
    "aggr_df['Vestas_Power_Max']=aggr_df['Wind_Speed_Max'].apply(Vestas_Power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df['Nordex_Power_Min']=aggr_df['Wind_Speed_Min'].apply(Nordex_Power)\n",
    "aggr_df['Nordex_Power_Max']=aggr_df['Wind_Speed_Max'].apply(Nordex_Power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df['Enercon_Power_Min']=aggr_df['Wind_Speed_Min'].apply(Enercon_Power)\n",
    "aggr_df['Enercon_Power_Max']=aggr_df['Wind_Speed_Max'].apply(Enercon_Power)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df['Vestas_Energy_Min_MWh']=aggr_df['Vestas_Power_Min']/1000\n",
    "aggr_df['Vestas_Energy_Max_MWh']=aggr_df['Vestas_Power_Max']/1000\n",
    "aggr_df['Nordex_Energy_Min_MWh']=aggr_df['Nordex_Power_Min']/1000\n",
    "aggr_df['Nordex_Energy_Max_MWh']=aggr_df['Nordex_Power_Max']/1000\n",
    "aggr_df['Enercon_Energy_Min_MWh']=aggr_df['Enercon_Power_Min']/1000\n",
    "aggr_df['Enercon_Energy_Max_MWh']=aggr_df['Enercon_Power_Max']/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add hours\n",
    "aggr_df['hour']=pd.Series(np.tile([1,1,2,2,3,3,4,4,5,5,6,6,7,7,8,8,9,9,10,10,11,11,12,12,13,13,14,14,15,15,16,16,17,17,18,18,19,19,20,20,21,21,22,22,23,23,24,24],int(len(aggr_df)/48)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes out matching errors\n",
    "aggr_df['lon']=aggr_df['lon'].round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate\n",
    "aggr_df=aggr_df.drop(columns=['time','Wind_Speed_Min','Wind_Speed_Max', 'Vestas_Power_Min', 'Vestas_Power_Max','Nordex_Power_Min','Nordex_Power_Max','Enercon_Power_Min','Enercon_Power_Max'])\n",
    "aggr_df=aggr_df.sort_values(by=['lat', 'lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df.to_csv('Wind_Energy_Polygons_Dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggr_df = pd.read_csv('Wind_Energy_Polygons_Dataframe.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append solar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar_df=pd.read_csv('Solar_Power.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create identifier for lookup\n",
    "solar_df['coords-season-hour']=solar_df['coords']+\"-\"+solar_df['season']+\"-\"+solar_df['hour'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create identifier for lookup\n",
    "aggr_df['coords-season-hour']=aggr_df['coords'].astype(str)+\"-\"+aggr_df['season']+\"-\"+aggr_df['hour'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join minimum solar energy value to the wind energy dataset\n",
    "aggr_df['SolarPV_Energy_Min_W']= aggr_df['coords-season-hour'].map(solar_df.set_index('coords-season-hour')['P_Min'].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join maximum solar energy value to the wind energy dataset\n",
    "aggr_df['SolarPV_Energy_Max_W']= aggr_df['coords-season-hour'].map(solar_df.set_index('coords-season-hour')['P_Max'].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the areas where no solar energy data was found (e.g. next to water)\n",
    "aggr_df['SolarPV_Energy_Min_W'] = aggr_df['SolarPV_Energy_Min_W'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the areas where no solar energy data was found (e.g. next to water)\n",
    "aggr_df['SolarPV_Energy_Max_W'] = aggr_df['SolarPV_Energy_Max_W'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df['SolarPV_Energy_Min_MWh']=aggr_df['SolarPV_Energy_Min_W']/1000000\n",
    "aggr_df['SolarPV_Energy_Max_MWh']=aggr_df['SolarPV_Energy_Max_W']/1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "aggr_df=aggr_df.drop(columns=['SolarPV_Energy_Min_W','SolarPV_Energy_Max_W'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create geodataframe for filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df=aggr_df.loc[(aggr_df['hour'] == 1)&(aggr_df['season'] == 'ss')]\n",
    "filter_df=filter_df.drop(columns=['lat','lon','season','Vestas_Energy_Min_MWh','Vestas_Energy_Max_MWh','Nordex_Energy_Min_MWh','Nordex_Energy_Max_MWh','Enercon_Energy_Min_MWh','Enercon_Energy_Max_MWh','SolarPV_Energy_Min_MWh','SolarPV_Energy_Max_MWh', 'hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_df['centroid']=filter_df['geometry'].apply(lambda x: x.centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_gdf = geopandas.GeoDataFrame(filter_df, geometry='geometry')\n",
    "filter_gdf=filter_gdf.set_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersect with countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_df = geopandas.read_file('/Users/alexandrapopova/Downloads/ref-countries-2020-60m.geojson/CNTR_RG_60M_2020_4326.geojson')\n",
    "CountryList = ['GBR', 'AUT', 'BEL', 'BGR', 'HRV', 'CYP', 'CZE', 'DNK', 'EST', 'FIN', 'FRA', 'DEU', 'GRC', 'HUN', 'IRL', 'ITA', 'LVA', 'LTU', 'LUX', 'MLT', 'NLD', 'POL', 'PRT', 'ROU', 'SVK', 'SVN', 'ESP', 'SWE']\n",
    "countries_df = countries_df[countries_df['ISO3_CODE'].isin(CountryList)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_df=countries_df.drop(columns=['id','CNTR_ID','CNTR_NAME', 'NAME_ENGL','FID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=geopandas.overlay(filter_gdf, countries_df, how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv('Polygons+Countries_Dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df = pd.read_csv('Polygons+Countries_Dataframe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_df['geometry']=results_df['geometry'].apply(wkt.loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results= geopandas.GeoDataFrame(results_df, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results=results.drop(columns=['Unnamed: 0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.drop(columns=['coords']).to_file(\"polygons+countries.geojson\", driver=\"GeoJSON\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intersect with Land use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#land use files are split into multiple due to large datasize - loaded here separately\n",
    "land_use_1 = geopandas.read_file('land_use_1_CDDA.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_use_2 = geopandas.read_file('land_use_2_CDDA.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_use_3 = geopandas.read_file('land_use_3_CDDA.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_use_4 = geopandas.read_file('land_use_4_CDDA.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_use_5 = geopandas.read_file('land_use_5_CDDA.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_use_6 = geopandas.read_file('land_use_6_CDDA.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_use_7 = geopandas.read_file('land_use_7_CDDA.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_use_8 = geopandas.read_file('land_use_8_CDDA.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_use_9 = geopandas.read_file('land_use_9_CDDA.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_use_10 = geopandas.read_file('land_use_10_CDDA.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "land_use_11 = geopandas.read_file('land_use_11_CDDA.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intersects energy data cells with land use polygons\n",
    "results_landuse_1=geopandas.overlay(results, land_use_1, how='intersection')\n",
    "results_landuse_2=geopandas.overlay(results, land_use_2, how='intersection')\n",
    "results_landuse_3=geopandas.overlay(results, land_use_3, how='intersection')\n",
    "results_landuse_4=geopandas.overlay(results, land_use_4, how='intersection')\n",
    "results_landuse_5=geopandas.overlay(results, land_use_5, how='intersection')\n",
    "results_landuse_6 =geopandas.overlay(results, land_use_6, how='intersection')\n",
    "results_landuse_7=geopandas.overlay(results, land_use_7, how='intersection')\n",
    "results_landuse_8=geopandas.overlay(results, land_use_8, how='intersection')\n",
    "results_landuse_9=geopandas.overlay(results, land_use_9, how='intersection')\n",
    "results_landuse_10=geopandas.overlay(results, land_use_10, how='intersection')\n",
    "results_landuse_11=geopandas.overlay(results, land_use_11, how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "results_landuse_1.to_file(\"land_use_polygons_simplify.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_landuse_1=geopandas.read_file('land_use_polygons_simplify.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_2.to_file(\"land_use_polygons_2_simplify.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_landuse_2=geopandas.read_file('land_use_polygons_2_simplify.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_3.to_file(\"land_use_polygons_3_simplify.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_landuse_3=geopandas.read_file('land_use_polygons_3_simplify.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_4.to_file(\"land_use_polygons_4_simplify.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_landuse_4=geopandas.read_file('land_use_polygons_4_simplify.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_5.to_file(\"land_use_polygons_5_simplify.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_landuse_5=geopandas.read_file('land_use_polygons_5_simplify.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_6.to_file(\"land_use_polygons_6_simplify.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_landuse_6=geopandas.read_file('land_use_polygons_6_simplify.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_7.to_file(\"land_use_polygons_7_simplify.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_landuse_7=geopandas.read_file('land_use_polygons_7_simplify.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_8.to_file(\"land_use_polygons_8_simplify.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_landuse_8=geopandas.read_file('land_use_polygons_8_simplify.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_9.to_file(\"land_use_polygons_9_simplify.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_landuse_9=geopandas.read_file('land_use_polygons_9_simplify.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_10.to_file(\"land_use_polygons_10_simplify.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_landuse_10=geopandas.read_file('land_use_polygons_10_simplify.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_11.to_file(\"land_use_polygons_11_simplify.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_landuse_11=geopandas.read_file('land_use_polygons_11_simplify.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result of the overlay is multipolygons - break into smaller polygons\n",
    "\n",
    "def breakintopolygons(results_landuse, results_landuse_polygons):\n",
    "    for i in range(len(results_landuse)):\n",
    "        if (type(results_landuse.geometry.iloc[i])==Polygon):\n",
    "            results_landuse_polygons=results_landuse_polygons.append(results_landuse.iloc[i])\n",
    "        else:\n",
    "            for j in range (len(results_landuse.geometry.iloc[i])):\n",
    "                if (results_landuse.geometry.iloc[i][j].area<0.0001):\n",
    "                    continue\n",
    "                else:\n",
    "                    row=results_landuse.iloc[i]\n",
    "                    row['geometry']=results_landuse.geometry.iloc[i][j]\n",
    "                    results_landuse_polygons=results_landuse_polygons.append(row)\n",
    "    return results_landuse_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_polygons_1 = geopandas.GeoDataFrame(columns=results_landuse_1.columns)\n",
    "results_landuse_polygons_1=breakintopolygons(results_landuse_1, results_landuse_polygons_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_polygons_2 = geopandas.GeoDataFrame(columns=results_landuse_2.columns)\n",
    "results_landuse_polygons_2=breakintopolygons(results_landuse_2, results_landuse_polygons_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_polygons_3 = geopandas.GeoDataFrame(columns=results_landuse_3.columns)\n",
    "results_landuse_polygons_3=breakintopolygons(results_landuse_3, results_landuse_polygons_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_polygons_4 = geopandas.GeoDataFrame(columns=results_landuse_4.columns)\n",
    "results_landuse_polygons_4=breakintopolygons(results_landuse_4, results_landuse_polygons_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_polygons_5 = geopandas.GeoDataFrame(columns=results_landuse_5.columns)\n",
    "results_landuse_polygons_5=breakintopolygons(results_landuse_5, results_landuse_polygons_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_polygons_6 = geopandas.GeoDataFrame(columns=results_landuse_6.columns)\n",
    "results_landuse_polygons_6=breakintopolygons(results_landuse_6, results_landuse_polygons_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_polygons_7 = geopandas.GeoDataFrame(columns=results_landuse_7.columns)\n",
    "results_landuse_polygons_7=breakintopolygons(results_landuse_7, results_landuse_polygons_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_polygons_8 = geopandas.GeoDataFrame(columns=results_landuse_8.columns)\n",
    "results_landuse_polygons_8=breakintopolygons(results_landuse_8, results_landuse_polygons_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_polygons_9 = geopandas.GeoDataFrame(columns=results_landuse_9.columns)\n",
    "results_landuse_polygons_9=breakintopolygons(results_landuse_9, results_landuse_polygons_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_6307/314263844.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults_landuse_polygons_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults_landuse_10\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mresults_landuse_polygons_10\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbreakintopolygons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_landuse_10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_landuse_polygons_10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_6307/861960249.py\u001b[0m in \u001b[0;36mbreakintopolygons\u001b[0;34m(results_landuse, results_landuse_polygons)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_landuse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_landuse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mPolygon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m             \u001b[0mresults_landuse_polygons\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresults_landuse_polygons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_landuse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_landuse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeometry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/geo_env2/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   8959\u001b[0m             \u001b[0mto_concat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8960\u001b[0m         return (\n\u001b[0;32m-> 8961\u001b[0;31m             concat(\n\u001b[0m\u001b[1;32m   8962\u001b[0m                 \u001b[0mto_concat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8963\u001b[0m                 \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/geo_env2/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/geo_env2/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/geo_env2/lib/python3.9/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             \u001b[0mcons\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 539\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcons\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"concat\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_result_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/geo_env2/lib/python3.9/site-packages/geopandas/geodataframe.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, geometry, crs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    136\u001b[0m                     )\n\u001b[1;32m    137\u001b[0m                     \u001b[0;31m# TODO: raise error in 0.9 or 0.10.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"geometry\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ensure_geometry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"geometry\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/geo_env2/lib/python3.9/site-packages/geopandas/geodataframe.py\u001b[0m in \u001b[0;36m_ensure_geometry\u001b[0;34m(data, crs)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mGeoSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfrom_shapely\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/geo_env2/lib/python3.9/site-packages/geopandas/array.py\u001b[0m in \u001b[0;36mfrom_shapely\u001b[0;34m(data, crs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \"\"\"\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mGeometryArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectorized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_shapely\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/geo_env2/lib/python3.9/site-packages/geopandas/_vectorized.py\u001b[0m in \u001b[0;36mfrom_shapely\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSE_PYGEOS\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpygeos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeometry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseGeometry\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUSE_PYGEOS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_shapely_to_pygeos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results_landuse_polygons_10 = geopandas.GeoDataFrame(columns=results_landuse_10.columns)\n",
    "results_landuse_polygons_10=breakintopolygons(results_landuse_10, results_landuse_polygons_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_polygons_11 = geopandas.GeoDataFrame(columns=results_landuse_10.columns)\n",
    "results_landuse_polygons_11=breakintopolygons(results_landuse_10, results_landuse_polygons_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_1=results_landuse_polygons_1\n",
    "results_landuse_2=results_landuse_polygons_2\n",
    "results_landuse_3=results_landuse_polygons_3\n",
    "results_landuse_4=results_landuse_polygons_4\n",
    "results_landuse_5=results_landuse_polygons_5\n",
    "results_landuse_6=results_landuse_polygons_6\n",
    "results_landuse_7=results_landuse_polygons_7\n",
    "results_landuse_8=results_landuse_polygons_8\n",
    "results_landuse_9=results_landuse_polygons_9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add lines cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('substations.csv')\n",
    "substations_gdf = geopandas.GeoDataFrame(\n",
    "    df, geometry=geopandas.points_from_xy(df.lon, df.lat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_15356/448186792.py:1: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  substations_gdf.to_file('substations.shp')\n"
     ]
    }
   ],
   "source": [
    "#substations_gdf.to_file('substations.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a KDTree to find the nearest neighbours\n",
    "point_array=np.empty((len(substations_gdf),2))\n",
    "for i in range(len(substations_gdf)):\n",
    "    point_array[i,0]=substations_gdf['geometry'][i].x\n",
    "    point_array[i,1]=substations_gdf['geometry'][i].y\n",
    "point_tree = spatial.cKDTree(point_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distance is measured to centroids - find centroids\n",
    "results_landuse_1['centroid']=results_landuse_1['geometry'].apply(lambda x: x.centroid)\n",
    "results_landuse_2['centroid']=results_landuse_2['geometry'].apply(lambda x: x.centroid)\n",
    "results_landuse_3['centroid']=results_landuse_3['geometry'].apply(lambda x: x.centroid)\n",
    "results_landuse_4['centroid']=results_landuse_4['geometry'].apply(lambda x: x.centroid)\n",
    "results_landuse_5['centroid']=results_landuse_5['geometry'].apply(lambda x: x.centroid)\n",
    "results_landuse_6['centroid']=results_landuse_6['geometry'].apply(lambda x: x.centroid)\n",
    "results_landuse_7['centroid']=results_landuse_7['geometry'].apply(lambda x: x.centroid)\n",
    "results_landuse_8['centroid']=results_landuse_8['geometry'].apply(lambda x: x.centroid)\n",
    "results_landuse_9['centroid']=results_landuse_9['geometry'].apply(lambda x: x.centroid)\n",
    "results_landuse_10['centroid']=results_landuse_10['geometry'].apply(lambda x: x.centroid)\n",
    "results_landuse_11['centroid']=results_landuse_11['geometry'].apply(lambda x: x.centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Haversine formula for kilometer distance between two lat/long points\n",
    "def haversine_dist_from_coords(lat1, lon1, lat2, lon2):\n",
    "    # The math module contains a function named radians which converts from degrees to radians.\n",
    "    lon1 = radians(lon1)\n",
    "    lon2 = radians(lon2)\n",
    "    lat1 = radians(lat1)\n",
    "    lat2 = radians(lat2)\n",
    "    # Haversine formula\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "    a = sin(dlat / 2) ** 2 + cos(lat1) * cos(lat2) * sin(dlon / 2) ** 2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    # Radius of earth in kilometers. Use 3956 for miles\n",
    "    r = 6371\n",
    "    # calculate and return the result\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lines_length (point, lines_df):\n",
    "    lines_df['distance']=lines_df['geometry'].apply(lambda z: haversine_dist_from_coords(z.x, z.y, point.x, point.y))\n",
    "    distance=(lines_df[['distance']].min())\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=SettingWithCopyWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_lines_cost (results_landuse_polygons):\n",
    "    results_landuse_polygons['lines_length']=np.nan\n",
    "    results_landuse_polygons['lines_cost']=np.nan\n",
    "    for p in range (len(results_landuse_polygons)):\n",
    "        nearest=(point_tree.query_ball_point([results_landuse_polygons['centroid'].iloc[p].x, results_landuse_polygons['centroid'].iloc[p].y], 1))\n",
    "        if (len(nearest)==0):\n",
    "            nearest=(point_tree.query_ball_point([results_landuse_polygons['centroid'].iloc[p].x, results_landuse_polygons['centroid'].iloc[p].y], 2))\n",
    "        if (len(nearest)==0):\n",
    "            nearest=(point_tree.query_ball_point([results_landuse_polygons['centroid'].iloc[p].x, results_landuse_polygons['centroid'].iloc[p].y], 20))\n",
    "        gdf_nearest_subs = geopandas.GeoDataFrame(columns=substations_gdf.columns)\n",
    "        gdf_nearest_subs=substations_gdf.iloc[(nearest)]\n",
    "        results_landuse_polygons['lines_length'].iloc[p]=lines_length(results_landuse_polygons['centroid'].iloc[p], gdf_nearest_subs)\n",
    "        price=95 #thousands euros per km\n",
    "        results_landuse_polygons['lines_cost']=results_landuse_polygons['lines_length']*price\n",
    "    return results_landuse_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_1=write_lines_cost(results_landuse_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_2=write_lines_cost(results_landuse_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_3=write_lines_cost(results_landuse_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_4=write_lines_cost(results_landuse_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_5=write_lines_cost(results_landuse_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_6=write_lines_cost(results_landuse_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_7=write_lines_cost(results_landuse_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_8=write_lines_cost(results_landuse_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_9=write_lines_cost(results_landuse_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_10=write_lines_cost(results_landuse_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_11=write_lines_cost(results_landuse_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "results_landuse_1.to_csv('results_landuse+costs_1.csv')\n",
    "results_landuse_2.to_csv('results_landuse+costs_2.csv')\n",
    "results_landuse_3.to_csv('results_landuse+costs_3.csv')\n",
    "results_landuse_4.to_csv('results_landuse+costs_4.csv')\n",
    "results_landuse_5.to_csv('results_landuse+costs_5.csv')\n",
    "results_landuse_6.to_csv('results_landuse+costs_6.csv')\n",
    "results_landuse_7.to_csv('results_landuse+costs_7.csv')\n",
    "results_landuse_8.to_csv('results_landuse+costs_8.csv')\n",
    "results_landuse_9.to_csv('results_landuse+costs_9.csv')\n",
    "results_landuse_10.to_csv('results_landuse+costs_10.csv')\n",
    "results_landuse_11.to_csv('results_landuse+costs_11.csv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add distance to roads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_gdf = geopandas.read_file('/Users/alexandrapopova/Downloads/europe-road.geojson')\n",
    "roads_gdf=roads_gdf[['rtn','geometry']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#same methodology as for the lines distance\n",
    "def road_distance (point, road_df):\n",
    "    road_df['closest_point']=road_df['geometry'].apply(lambda x: x.interpolate(x.project(point)))\n",
    "    road_df['distance']=road_df['closest_point'].apply(lambda z: haversine_dist_from_coords(z.x, z.y, point.x, point.y))\n",
    "    distance=(road_df[['distance']].min())\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "roads_gdf['centroid']=roads_gdf['geometry'].apply(lambda x: x.centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroid_array=np.empty((len(roads_gdf),2))\n",
    "for i in range(len(roads_gdf)):\n",
    "    centroid_array[i,0]=roads_gdf['centroid'][i].x\n",
    "    centroid_array[i,1]=roads_gdf['centroid'][i].y\n",
    "point_tree = spatial.cKDTree(centroid_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_to_roads(results_landuse_polygons):\n",
    "    results_landuse_polygons['distance_to_roads'] = np.nan\n",
    "    for p in range (len(results_landuse_polygons)):\n",
    "        nearest=(point_tree.query_ball_point([results_landuse_polygons['centroid'].iloc[p].x, results_landuse_polygons['centroid'].iloc[p].y], 1))\n",
    "        if (len(nearest)==0):\n",
    "            nearest=(point_tree.query_ball_point([results_landuse_polygons['centroid'].iloc[p].x, results_landuse_polygons['centroid'].iloc[p].y], 2))\n",
    "        if (len(nearest)==0):\n",
    "            nearest=(point_tree.query_ball_point([results_landuse_polygons['centroid'].iloc[p].x, results_landuse_polygons['centroid'].iloc[p].y], 20))\n",
    "        gdf_nearest_roads = geopandas.GeoDataFrame(columns=roads_gdf.columns)\n",
    "        gdf_nearest_roads=roads_gdf.iloc[(nearest)]\n",
    "        results_landuse_polygons['distance_to_roads'].iloc[p]= road_distance(results_landuse_polygons['centroid'].iloc[p], gdf_nearest_roads)\n",
    "        price=70 #thousand euros per km\n",
    "        results_landuse_polygons['road_cost']=results_landuse_polygons['distance_to_roads']*price\n",
    "    return results_landuse_polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_1=distance_to_roads(results_landuse_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_2=distance_to_roads(results_landuse_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_3=distance_to_roads(results_landuse_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_4=distance_to_roads(results_landuse_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_5=distance_to_roads(results_landuse_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_6=distance_to_roads(results_landuse_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_7=distance_to_roads(results_landuse_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_8=distance_to_roads(results_landuse_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_9=distance_to_roads(results_landuse_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_10=distance_to_roads(results_landuse_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_11=distance_to_roads(results_landuse_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "results_landuse_1.to_csv('results_landuse+costs_1.csv')\n",
    "results_landuse_2.to_csv('results_landuse+costs_2.csv')\n",
    "results_landuse_3.to_csv('results_landuse+costs_3.csv')\n",
    "results_landuse_4.to_csv('results_landuse+costs_4.csv')\n",
    "results_landuse_5.to_csv('results_landuse+costs_5.csv')\n",
    "results_landuse_6.to_csv('results_landuse+costs_6.csv')\n",
    "results_landuse_7.to_csv('results_landuse+costs_7.csv')\n",
    "results_landuse_8.to_csv('results_landuse+costs_8.csv')\n",
    "results_landuse_9.to_csv('results_landuse+costs_9.csv')\n",
    "results_landuse_10.to_csv('results_landuse+costs_10.csv')\n",
    "results_landuse_11.to_csv('results_landuse+costs_11.csv')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map bidding zones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join all separate files\n",
    "results_landuse_polygons=results_landuse_1.append(results_landuse_2).append(results_landuse_3).append(results_landuse_4).append(results_landuse_5).append(results_landuse_6).append(results_landuse_7).append(results_landuse_8).append(results_landuse_9).append(results_landuse_10).append(results_landuse_11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "italy_gdf = geopandas.read_file('/Users/alexandrapopova/Downloads/Italy_Zones.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweden_gdf = geopandas.read_file('/Users/alexandrapopova/Downloads/Sweden_Zones.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "denmark_gdf = geopandas.read_file('/Users/alexandrapopova/Downloads/Denmark_Zones.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "italy_gdf = italy_gdf.dissolve(by='zone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "denmark_gdf = denmark_gdf.dissolve(by='zone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "italy_gdf=italy_gdf.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "denmark_gdf=denmark_gdf.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_zones=results_landuse_polygons.loc[(results_landuse_polygons['ISO3_CODE'] != 'ITA')&(results_landuse_polygons['ISO3_CODE'] != 'SWE')&(results_landuse_polygons['ISO3_CODE'] != 'DNK')]\n",
    "results_landuse_italy=results_landuse_polygons.loc[(results_landuse_polygons['ISO3_CODE'] == 'ITA')]\n",
    "results_landuse_sweden=results_landuse_polygons.loc[(results_landuse_polygons['ISO3_CODE'] == 'SWE')]\n",
    "results_landuse_denmark=results_landuse_polygons.loc[(results_landuse_polygons['ISO3_CODE'] == 'DNK')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_9298/3509756867.py:1: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: None\n",
      "Right CRS: EPSG:4326\n",
      "\n",
      "  results_landuse_italy=geopandas.overlay(results_landuse_italy, italy_gdf, how='intersection')\n"
     ]
    }
   ],
   "source": [
    "#intersect with bidding zones\n",
    "results_landuse_italy=geopandas.overlay(results_landuse_italy, italy_gdf, how='intersection')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_9298/534446838.py:1: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: None\n",
      "Right CRS: EPSG:4326\n",
      "\n",
      "  results_landuse_sweden=geopandas.overlay(results_landuse_sweden, sweden_gdf, how='intersection')\n"
     ]
    }
   ],
   "source": [
    "#intersect with bidding zones\n",
    "results_landuse_sweden=geopandas.overlay(results_landuse_sweden, sweden_gdf, how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_9298/95641466.py:1: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: None\n",
      "Right CRS: EPSG:4326\n",
      "\n",
      "  results_landuse_denmark=geopandas.overlay(results_landuse_denmark, denmark_gdf, how='intersection')\n"
     ]
    }
   ],
   "source": [
    "#intersect with bidding zones\n",
    "results_landuse_denmark=geopandas.overlay(results_landuse_denmark, denmark_gdf, how='intersection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create zone code\n",
    "results_landuse_sweden['zone']=results_landuse_sweden['ISO3_CODE']+'-'+results_landuse_sweden['zone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_zones['zone']=results_landuse_zones['ISO3_CODE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#join all bidding zones back together\n",
    "results_landuse_zones=results_landuse_zones.append(results_landuse_italy).append(results_landuse_sweden).append(results_landuse_denmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_zones=results_landuse_zones.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_zones=results_landuse_zones.drop(columns=['FID', 'index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter out small polygons\n",
    "results_landuse_zones=results_landuse_zones.loc[(results_landuse_zones['geometry'].area>0.0001)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_landuse_zones.to_csv('results_landuse_cost_zones.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append energy by hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#at this point the dataset is split into all possible polygons, \n",
    "#but has only 1 line for each location - need to multiply it by seasons and hour\n",
    "\n",
    "results_landuse_zones['hour']=1\n",
    "results_landuse_zones['season']=\"ss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_landuse_zones['hour']=1\n",
    "results_landuse_zones['season']=\"ss\"\n",
    "df_expanded=results_landuse_zones.copy()\n",
    "\n",
    "for h in range(23):\n",
    "    results_landuse_zones['hour']=h+2\n",
    "    df_expanded=df_expanded.append(results_landuse_zones)\n",
    "\n",
    "results_landuse_zones['hour']=1\n",
    "results_landuse_zones['season']=\"aw\"\n",
    "df_expanded=df_expanded.append(results_landuse_zones)\n",
    "for h in range(23):\n",
    "    results_landuse_zones['hour']=h+2\n",
    "    df_expanded=df_expanded.append(results_landuse_zones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded=df_expanded.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded=df_expanded.sort_values(by=['index', 'hour','season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded['coords-season-hour'] = df_expanded['coords']+'-'+ df_expanded['season']+'-'+ df_expanded['hour'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append energy values by location, hour, zone\n",
    "df_expanded['Vestas_Energy_Min_MWh'] = df_expanded['coords-season-hour'].map(aggr_df.set_index('coords-season-hour')['Vestas_Energy_Min_MWh'].to_dict())\n",
    "df_expanded['Vestas_Energy_Max_MWh'] = df_expanded['coords-season-hour'].map(aggr_df.set_index('coords-season-hour')['Vestas_Energy_Max_MWh'].to_dict())\n",
    "df_expanded['Nordex_Energy_Min_MWh'] = df_expanded['coords-season-hour'].map(aggr_df.set_index('coords-season-hour')['Nordex_Energy_Min_MWh'].to_dict())\n",
    "df_expanded['Nordex_Energy_Max_MWh'] = df_expanded['coords-season-hour'].map(aggr_df.set_index('coords-season-hour')['Nordex_Energy_Max_MWh'].to_dict())\n",
    "df_expanded['Enercon_Energy_Min_MWh'] = df_expanded['coords-season-hour'].map(aggr_df.set_index('coords-season-hour')['Enercon_Energy_Min_MWh'].to_dict())\n",
    "df_expanded['Enercon_Energy_Max_MWh'] = df_expanded['coords-season-hour'].map(aggr_df.set_index('coords-season-hour')['Enercon_Energy_Max_MWh'].to_dict())\n",
    "df_expanded['SolarPV_Energy_Min_MWh'] = df_expanded['coords-season-hour'].map(aggr_df.set_index('coords-season-hour')['SolarPV_Energy_Min_MWh'].to_dict())\n",
    "df_expanded['SolarPV_Energy_Max_MWh'] = df_expanded['coords-season-hour'].map(aggr_df.set_index('coords-season-hour')['SolarPV_Energy_Max_MWh'].to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append costs and prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "OM_cost_df = pd.read_csv('OM_cost.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append O&M costs based on the country code\n",
    "df_expanded['OM cost, EUR/kWh'] = df_expanded['ISO3_CODE'].map(OM_cost_df.set_index('Country')['OM cost, EUR/kWh'].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df = pd.read_csv('Price by country.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create identifier for lookups\n",
    "df_expanded['Zone-Season-Hour']=df_expanded['zone']+\"-\"+df_expanded['season']+\"-\"+df_expanded['hour'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append prices based on the zone/season/hour identifier\n",
    "df_expanded['Price, EUR/MWh']= df_expanded['Zone-Season-Hour'].map(price_df.set_index('Zone - Season - Hour')['Price'].to_dict())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "wacc_df = pd.read_csv('WACC by country.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#append WACC based on the country code\n",
    "df_expanded['WACC, %']= df_expanded['ISO3_CODE'].map(wacc_df.set_index('Country')['WACC, %'].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all locations now have all technical and economic metrics attached\n",
    "df_expanded.to_csv('df_expanded_preNPV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/geo_env2/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "#df_expanded=pd.read_csv('df_expanded_preNPV.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NPV calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create identifier of location alternative\n",
    "df_expanded = df_expanded.assign(loc_id=(df_expanded['geometry']).astype('category').cat.codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded =df_expanded.sort_values(by=['loc_id', 'season','hour'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Revenue = Price x Energy\n",
    "def Recurring_Revenue (season, energy, price):\n",
    "    recurring_revenue=np.where((season=='ss'), energy*(price)*184, energy*(price)*181)\n",
    "    return recurring_revenue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#O&M Costs = O&M per kWh x Energy\n",
    "def Recurring_Cost (season, energy, OM):\n",
    "    recurring_cost=np.where((season=='ss'), energy*(OM*1000)*184, energy*(OM*1000)*181)\n",
    "    return recurring_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find mean energy values\n",
    "df_expanded['Vestas_Energy_Mean_MWh']=df_expanded['Vestas_Energy_Min_MWh']+(df_expanded['Vestas_Energy_Max_MWh']-df_expanded['Vestas_Energy_Min_MWh'])/2\n",
    "df_expanded['Nordex_Energy_Mean_MWh']=df_expanded['Nordex_Energy_Min_MWh']+(df_expanded['Nordex_Energy_Max_MWh']-df_expanded['Nordex_Energy_Min_MWh'])/2\n",
    "df_expanded['Enercon_Energy_Mean_MWh']=df_expanded['Enercon_Energy_Min_MWh']+(df_expanded['Enercon_Energy_Max_MWh']-df_expanded['Enercon_Energy_Min_MWh'])/2\n",
    "df_expanded['SolarPV_Energy_Mean_MWh']=df_expanded['SolarPV_Energy_Min_MWh']+(df_expanded['SolarPV_Energy_Max_MWh']-df_expanded['SolarPV_Energy_Min_MWh'])/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate revenues and O&M costs\n",
    "df_expanded['Vestas_Recurring_Revenue']=Recurring_Revenue(df_expanded['season'],df_expanded['Vestas_Energy_Mean_MWh'],df_expanded['Price, EUR/MWh'])\n",
    "df_expanded['Nordex_Recurring_Revenue']=Recurring_Revenue(df_expanded['season'],df_expanded['Nordex_Energy_Mean_MWh'],df_expanded['Price, EUR/MWh'])\n",
    "df_expanded['Enercon_Recurring_Revenue']=Recurring_Revenue(df_expanded['season'],df_expanded['Enercon_Energy_Mean_MWh'],df_expanded['Price, EUR/MWh'])\n",
    "df_expanded['SolarPV_Recurring_Revenue']=Recurring_Revenue(df_expanded['season'],df_expanded['SolarPV_Energy_Mean_MWh'],df_expanded['Price, EUR/MWh'])\n",
    "\n",
    "df_expanded['Vestas_Recurring_Cost']=Recurring_Cost(df_expanded['season'],df_expanded['Vestas_Energy_Mean_MWh'],df_expanded['OM cost, EUR/kWh'])\n",
    "df_expanded['Nordex_Recurring_Cost']=Recurring_Cost(df_expanded['season'],df_expanded['Nordex_Energy_Mean_MWh'],df_expanded['OM cost, EUR/kWh'])\n",
    "df_expanded['Enercon_Recurring_Cost']=Recurring_Cost(df_expanded['season'],df_expanded['Enercon_Energy_Mean_MWh'],df_expanded['OM cost, EUR/kWh'])\n",
    "df_expanded['SolarPV_Recurring_Cost']=Recurring_Cost(df_expanded['season'],df_expanded['SolarPV_Energy_Mean_MWh'],df_expanded['OM cost, EUR/kWh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate into annual values\n",
    "df_expanded_sum=df_expanded.groupby(['loc_id']).agg({'Vestas_Recurring_Revenue': ['sum'],\n",
    "                                                        'Nordex_Recurring_Revenue': ['sum'],\n",
    "                                                        'Enercon_Recurring_Revenue': ['sum'],\n",
    "                                                        'SolarPV_Recurring_Revenue': ['sum'],\n",
    "                                                        'Vestas_Recurring_Cost': ['sum'],\n",
    "                                                        'Nordex_Recurring_Cost': ['sum'],\n",
    "                                                        'Enercon_Recurring_Cost': ['sum'],\n",
    "                                                        'SolarPV_Recurring_Cost': ['sum'],\n",
    "                                                        'Vestas_Energy_Mean_MWh':['sum'],\n",
    "                                                        'Nordex_Energy_Mean_MWh':['sum'],\n",
    "                                                        'Enercon_Energy_Mean_MWh':['sum'],\n",
    "                                                        'SolarPV_Energy_Mean_MWh':['sum']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_sum=df_expanded_sum.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_sum.columns=df_expanded_sum.columns.droplevel(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Daily energy sum needs to be divided by 2 to find average between the 2 seasons\n",
    "df_expanded_sum['Vestas_Energy_Mean_MWh']=df_expanded_sum['Vestas_Energy_Mean_MWh']/2\n",
    "df_expanded_sum['Nordex_Energy_Mean_MWh']=df_expanded_sum['Nordex_Energy_Mean_MWh']/2\n",
    "df_expanded_sum['Enercon_Energy_Mean_MWh']=df_expanded_sum['Enercon_Energy_Mean_MWh']/2\n",
    "df_expanded_sum['SolarPV_Energy_Mean_MWh']=df_expanded_sum['SolarPV_Energy_Mean_MWh']/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append information fields\n",
    "df_expanded_sum['Country']=df_expanded_sum['loc_id'].map(df_expanded.set_index('loc_id')['ISO3_CODE'].to_dict())\n",
    "df_expanded_sum['Zone']=df_expanded_sum['loc_id'].map(df_expanded.set_index('loc_id')['zone'].to_dict())\n",
    "df_expanded_sum['Line_Length_km']=df_expanded_sum['loc_id'].map(df_expanded.set_index('loc_id')['lines_length'].to_dict())\n",
    "df_expanded_sum['Lines_Cost_kEUR']=df_expanded_sum['loc_id'].map(df_expanded.set_index('loc_id')['lines_cost'].to_dict())\n",
    "df_expanded_sum['Distance_to_roads_km']=df_expanded_sum['loc_id'].map(df_expanded.set_index('loc_id')['distance_to_roads'].to_dict())\n",
    "df_expanded_sum['Road_Cost_kEUR']=df_expanded_sum['loc_id'].map(df_expanded.set_index('loc_id')['road_cost'].to_dict())\n",
    "df_expanded_sum['WACC, %']=df_expanded_sum['loc_id'].map(df_expanded.set_index('loc_id')['WACC, %'].to_dict())\n",
    "df_expanded_sum['geometry']=df_expanded_sum['loc_id'].map(df_expanded.set_index('loc_id')['geometry'].to_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate present value of recurring profits\n",
    "df_expanded_sum['Vestas Profit PV, kEUR']=((df_expanded_sum['Vestas_Recurring_Revenue']-df_expanded_sum['Vestas_Recurring_Cost'])/1000)*(1-(1+df_expanded_sum['WACC, %']/100)**(-30))/(df_expanded_sum['WACC, %']/100)\n",
    "df_expanded_sum['Nordex Profit PV, kEUR']=((df_expanded_sum['Nordex_Recurring_Revenue']-df_expanded_sum['Nordex_Recurring_Cost'])/1000)*(1-(1+df_expanded_sum['WACC, %']/100)**(-30))/(df_expanded_sum['WACC, %']/100)\n",
    "df_expanded_sum['Enercon Profit PV, kEUR']=((df_expanded_sum['Enercon_Recurring_Revenue']-df_expanded_sum['Enercon_Recurring_Cost'])/1000)*(1-(1+df_expanded_sum['WACC, %']/100)**(-30))/(df_expanded_sum['WACC, %']/100)\n",
    "df_expanded_sum['SolarPV Profit PV, kEUR']=((df_expanded_sum['SolarPV_Recurring_Revenue']-df_expanded_sum['SolarPV_Recurring_Cost'])/1000)*(1-(1+df_expanded_sum['WACC, %']/100)**(-30))/(df_expanded_sum['WACC, %']/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate investment costs\n",
    "df_expanded_sum['Vestas Investment Cost, kEUR']=1000+8.5*3.5+100+df_expanded_sum['Lines_Cost_kEUR']+df_expanded_sum['Road_Cost_kEUR']\n",
    "df_expanded_sum['Nordex Investment Cost, kEUR']=500+8.5*2.5+100+df_expanded_sum['Lines_Cost_kEUR']+df_expanded_sum['Road_Cost_kEUR']\n",
    "df_expanded_sum['Enercon Investment Cost, kEUR']=200+8.5*0.8+100+df_expanded_sum['Lines_Cost_kEUR']+df_expanded_sum['Road_Cost_kEUR']\n",
    "df_expanded_sum['SolarPV Investment Cost, kEUR']=750+8.5+100+df_expanded_sum['Lines_Cost_kEUR']+df_expanded_sum['Road_Cost_kEUR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate NPV\n",
    "df_expanded_sum['Vestas NPV, kEUR']=df_expanded_sum['Vestas Profit PV, kEUR']-df_expanded_sum['Vestas Investment Cost, kEUR']\n",
    "df_expanded_sum['Nordex NPV, kEUR']=df_expanded_sum['Nordex Profit PV, kEUR']-df_expanded_sum['Nordex Investment Cost, kEUR']\n",
    "df_expanded_sum['Enercon NPV, kEUR']=df_expanded_sum['Enercon Profit PV, kEUR']-df_expanded_sum['Enercon Investment Cost, kEUR']\n",
    "df_expanded_sum['SolarPV NPV, kEUR']=df_expanded_sum['SolarPV Profit PV, kEUR']-df_expanded_sum['SolarPV Investment Cost, kEUR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_IRR(cf):\n",
    "    cashflow=np.empty(31)\n",
    "    cashflow.fill(cf[1])\n",
    "    cashflow[0]=cf[0]\n",
    "    irr = round(npf.irr(cashflow),4)\n",
    "    return irr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate Cash Flow for IRR definition\n",
    "df_expanded_sum['Vestas CF']=list(zip(-df_expanded_sum['Vestas Investment Cost, kEUR'],(df_expanded_sum['Vestas_Recurring_Revenue']-df_expanded_sum['Vestas_Recurring_Cost'])/1000))\n",
    "df_expanded_sum['Nordex CF']=list(zip(-df_expanded_sum['Nordex Investment Cost, kEUR'],(df_expanded_sum['Nordex_Recurring_Revenue']-df_expanded_sum['Nordex_Recurring_Cost'])/1000))\n",
    "df_expanded_sum['Enercon CF']=list(zip(-df_expanded_sum['Enercon Investment Cost, kEUR'],(df_expanded_sum['Enercon_Recurring_Revenue']-df_expanded_sum['Enercon_Recurring_Cost'])/1000))\n",
    "df_expanded_sum['SolarPV CF']=list(zip(-df_expanded_sum['SolarPV Investment Cost, kEUR'],(df_expanded_sum['SolarPV_Recurring_Revenue']-df_expanded_sum['SolarPV_Recurring_Cost'])/1000))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate IRR\n",
    "df_expanded_sum['Vestas IRR']=df_expanded_sum['Vestas CF'].apply(lambda x: calc_IRR(x))\n",
    "df_expanded_sum['Nordex IRR']=df_expanded_sum['Nordex CF'].apply(lambda x: calc_IRR(x))\n",
    "df_expanded_sum['Enercon IRR']=df_expanded_sum['Enercon CF'].apply(lambda x: calc_IRR(x))\n",
    "df_expanded_sum['SolarPV IRR']=df_expanded_sum['SolarPV CF'].apply(lambda x: calc_IRR(x))\n",
    "                                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate IRR\n",
    "df_expanded_sum['Vestas Payback']=round(df_expanded_sum['Vestas Investment Cost, kEUR']*1000/(df_expanded_sum['Vestas_Recurring_Revenue']-df_expanded_sum['Vestas_Recurring_Cost']),2)\n",
    "df_expanded_sum['Nordex Payback']=round(df_expanded_sum['Nordex Investment Cost, kEUR']*1000/(df_expanded_sum['Nordex_Recurring_Revenue']-df_expanded_sum['Nordex_Recurring_Cost']),2)\n",
    "df_expanded_sum['Enercon Payback']=round(df_expanded_sum['Enercon Investment Cost, kEUR']*1000/(df_expanded_sum['Enercon_Recurring_Revenue']-df_expanded_sum['Enercon_Recurring_Cost']),2)\n",
    "df_expanded_sum['SolarPV Payback']=round(df_expanded_sum['SolarPV Investment Cost, kEUR']*1000/(df_expanded_sum['SolarPV_Recurring_Revenue']-df_expanded_sum['SolarPV_Recurring_Cost']),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_sum=df_expanded_sum.drop(columns=['Vestas CF','Nordex CF','Enercon CF','SolarPV CF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPV_gdf = geopandas.GeoDataFrame(df_expanded_sum, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPV_gdf.to_file(\"NPV_map.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EPSG:4326 needed for area caclulation\n",
    "NPV_gdf=NPV_gdf.set_crs(\"EPSG:4326\")\n",
    "NPV_gdf_epsg3857=NPV_gdf.to_crs({'init': 'epsg:3857'})\n",
    "NPV_gdf_epsg3857['area']=NPV_gdf_epsg3857['geometry'].area/10**6\n",
    "NPV_gdf_epsg3857=NPV_gdf_epsg3857[['loc_id','area']]\n",
    "NPV_gdf_epsg3857.to_csv(\"NPV_epsg3857.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_expanded_sum=geopandas.read_file(\"NPV_map.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_2341/871543147.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_expanded_sum['Average_NPV'][i]=(df_expanded_sum['Vestas NPV, kEUR'][i]+df_expanded_sum['Nordex NPV, kEUR'][i]+df_expanded_sum['Enercon NPV, kEUR'][i])/3\n",
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_2341/871543147.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_expanded_sum['Average_NPV'][i]=(df_expanded_sum['Vestas NPV, kEUR'][i]+df_expanded_sum['Nordex NPV, kEUR'][i]+df_expanded_sum['Enercon NPV, kEUR'][i]+df_expanded_sum['SolarPV NPV, kEUR'][i])/4\n"
     ]
    }
   ],
   "source": [
    "#calculate average NPV between 4 technologies\n",
    "df_expanded_sum['Average_NPV']=0\n",
    "for i in range(len(df_expanded_sum)):\n",
    "    if df_expanded_sum['SolarPV_Energy_Mean_MWh'][i]==0:\n",
    "        df_expanded_sum['Average_NPV'][i]=(df_expanded_sum['Vestas NPV, kEUR'][i]+df_expanded_sum['Nordex NPV, kEUR'][i]+df_expanded_sum['Enercon NPV, kEUR'][i])/3\n",
    "    else:\n",
    "        df_expanded_sum['Average_NPV'][i]=(df_expanded_sum['Vestas NPV, kEUR'][i]+df_expanded_sum['Nordex NPV, kEUR'][i]+df_expanded_sum['Enercon NPV, kEUR'][i]+df_expanded_sum['SolarPV NPV, kEUR'][i])/4   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify to polygons - for web-tool display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_sum['geometry']=df_expanded_sum['geometry'].apply(lambda x: wkt.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_sum['centroid']=df_expanded_sum['geometry'].apply(lambda x: x.centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_2341/558145808.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_expanded_sum['polygon'][i]=str(results['geometry'][j])\n"
     ]
    }
   ],
   "source": [
    "#assign each location polygon to a cell\n",
    "for i in range (len(df_expanded_sum)):\n",
    "    point=df_expanded_sum['centroid'][i]\n",
    "    for j in range (len(results)):\n",
    "        if point.within(results['geometry'][j]):\n",
    "            df_expanded_sum['polygon'][i]=str(results['geometry'][j])\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find total cell area - for average weighted NPV\n",
    "df_expanded_sum['polygon_area']=df_expanded_sum['polygon'].apply(lambda x: x.area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the location area - for average weighted NPV\n",
    "df_expanded_sum['accessible_area']=df_expanded_sum['geometry'].apply(lambda x: x.area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weigh the NPV Average for 4 equipment models\n",
    "df_expanded_sum['weighted_NPV_Average']=df_expanded_sum['accessible_area']*df_expanded_sum['Average_NPV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weigh the NPV Average for Vestas\n",
    "df_expanded_sum['weighted_NPV_Vestas']=df_expanded_sum['accessible_area']*df_expanded_sum['Vestas NPV, kEUR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate by cell\n",
    "df_expanded_sum['polygon']=df_expanded_sum['polygon'].astype(str)\n",
    "df_expanded_polygons=df_expanded_sum.groupby(['polygon'] ).agg({'weighted_NPV_Average': ['sum'],'weighted_NPV_Vestas': ['sum'],'polygon_area':['mean']})\n",
    "df_expanded_polygons=df_expanded_polygons.reset_index()\n",
    "df_expanded_polygons.columns=df_expanded_polygons.columns.droplevel(-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find average weighted NPV\n",
    "df_expanded_polygons['average_weighted_NPV_all']=df_expanded_polygons['weighted_NPV_Average']/df_expanded_polygons['polygon_area']\n",
    "df_expanded_polygons['average_weighted_NPV_Vestas']=df_expanded_polygons['weighted_NPV_Vestas']/df_expanded_polygons['polygon_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_expanded_polygons['polygon']=df_expanded_polygons['polygon'].apply(lambda x: shapely.wkt.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "NPV_polygons_gdf = geopandas.GeoDataFrame(df_expanded_polygons, geometry='polygon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_2341/3768200808.py:1: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  NPV_polygons_gdf.to_file(\"NPV_polygons_map.shp\")\n"
     ]
    }
   ],
   "source": [
    "NPV_polygons_gdf.to_file(\"NPV_polygons_map.shp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost optimisation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create array with location attribution to zones\n",
    "zone_list=df_expanded_sum['Zone'].drop_duplicates().sort_values().reset_index()['Zone'].tolist()\n",
    "loc_zones = pd.DataFrame(0, index=range(0,len(df_expanded_sum)),columns=zone_list)\n",
    "\n",
    "for column in loc_zones:\n",
    "    for i in range(0,len(df_expanded_sum)):\n",
    "        if (df_expanded_sum.Zone[i]==column):\n",
    "            loc_zones[column][i]=1\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "loc_zones_array=loc_zones.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import savetxt\n",
    "from numpy import loadtxt\n",
    "savetxt('loc_zones_array.csv', loc_zones_array, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask array for zone selection\n",
    "selected_zone='FRA'\n",
    "df_expanded_sum['mask']=np.where((df_expanded_sum['Zone']==selected_zone), 1, 0)\n",
    "mask_array=df_expanded_sum['mask'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_15356/2388968071.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  energy_df['Nordex'][i]=np.array(df_expanded[df_expanded['loc_id']==i]['Nordex_Energy_Max_MWh']).astype(object)\n",
      "/opt/anaconda3/envs/geo_env2/lib/python3.9/site-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_15356/2388968071.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  energy_df['Enercon'][i]=np.array(df_expanded[df_expanded['loc_id']==i]['Enercon_Energy_Max_MWh']).astype(object)\n",
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_15356/2388968071.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  energy_df['SolarPV'][i]=np.array(df_expanded[df_expanded['loc_id']==i]['SolarPV_Energy_Max_MWh']).astype(object)\n"
     ]
    }
   ],
   "source": [
    "#create energy array\n",
    "energy_df = pd.DataFrame(0, index=range(0,len(df_expanded_sum)),columns=['Vestas', 'Nordex', 'Enercon', 'SolarPV'])\n",
    "\n",
    "for i in range(0,len(df_expanded_sum)):\n",
    "    energy_df['Vestas'][i]=np.array(df_expanded[df_expanded['loc_id']==i]['Vestas_Energy_Max_MWh']).astype(object)\n",
    "    energy_df['Nordex'][i]=np.array(df_expanded[df_expanded['loc_id']==i]['Nordex_Energy_Max_MWh']).astype(object)\n",
    "    energy_df['Enercon'][i]=np.array(df_expanded[df_expanded['loc_id']==i]['Enercon_Energy_Max_MWh']).astype(object)\n",
    "    energy_df['SolarPV'][i]=np.array(df_expanded[df_expanded['loc_id']==i]['SolarPV_Energy_Max_MWh']).astype(object)\n",
    "    \n",
    "energy_array=energy_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aggregate by season\n",
    "energy_array_seasonal = np.zeros((len(df_expanded_sum),4,2)) \n",
    "for i in range(len(df_expanded_sum)):\n",
    "    for e in range(4):\n",
    "        energy_array_seasonal[i][e][0]=sum(energy_array[i][e][0:24])\n",
    "        energy_array_seasonal[i][e][1]=sum(energy_array[i][e][24:48])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into 2 arrays - for loading into the web tool\n",
    "energy_array_aw = np.zeros((len(df_expanded_sum),4)) \n",
    "energy_array_ss = np.zeros((len(df_expanded_sum),4)) \n",
    "\n",
    "for i in range(len(df_expanded_sum)):\n",
    "    for e in range(4):\n",
    "        energy_array_aw[i][e]=sum(energy_array[i][e][0:24])\n",
    "        energy_array_ss[i][e]=sum(energy_array[i][e][24:48])\n",
    "        \n",
    "savetxt('energy_array_aw.csv', energy_array_aw, delimiter=',')\n",
    "savetxt('energy_array_ss.csv', energy_array_ss, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_15356/1082714821.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  demand_const[column][0]=(np.array(demand_df[column])).astype(object)\n"
     ]
    }
   ],
   "source": [
    "#create demand array by season, for constraining energy production\n",
    "demand_df=pd.read_csv('Net_Demand_Seasonal.csv')\n",
    "demand_const= pd.DataFrame(0, index=range(0,1),columns=zone_list)\n",
    "for column in demand_const:\n",
    "    demand_const[column][0]=(np.array(demand_df[column])).astype(object)\n",
    "demand_const_array=demand_const.to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into 2 arrays - for loading into the web tool\n",
    "demand_array_aw = np.zeros((len(demand_const_array))) \n",
    "demand_array_ss = np.zeros((len(demand_const_array))) \n",
    "for i in range(len(demand_const_array)):\n",
    "    demand_array_aw[i]=demand_const_array[i][0]\n",
    "    demand_array_ss[i]=demand_const_array[i][1]\n",
    "savetxt('demand_array_aw.csv', demand_array_aw, delimiter=',')\n",
    "savetxt('demand_array_ss.csv', demand_array_ss, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create array of area constraints\n",
    "loc_area=NPV_gdf_epsg3857['area'].to_numpy()\n",
    "savetxt('loc_area.csv', loc_area, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model variable coefficients\n",
    "v_cost=df_expanded_sum['Vestas Investment Cost, kEUR'].to_numpy()\n",
    "n_cost=df_expanded_sum['Nordex Investment Cost, kEUR'].to_numpy()\n",
    "e_cost=df_expanded_sum['Enercon Investment Cost, kEUR'].to_numpy()\n",
    "s_cost=df_expanded_sum['SolarPV Investment Cost, kEUR'].to_numpy()\n",
    "\n",
    "v_NPV=df_expanded_sum['Vestas NPV, kEUR'].to_numpy()\n",
    "n_NPV=df_expanded_sum['Nordex NPV, kEUR'].to_numpy()\n",
    "e_NPV=df_expanded_sum['Enercon NPV, kEUR'].to_numpy()\n",
    "s_NPV=df_expanded_sum['SolarPV NPV, kEUR'].to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 126543 rows, 505872 columns and 1998218 nonzeros\n",
      "Model fingerprint: 0x51ef5253\n",
      "Variable types: 0 continuous, 505872 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-02, 2e+05]\n",
      "  Objective range  [1e-02, 2e+04]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 5e+05]\n",
      "Found heuristic solution: objective 84732.790414\n",
      "Presolve removed 120557 rows and 487705 columns\n",
      "Presolve time: 0.83s\n",
      "Presolved: 5986 rows, 18167 columns, 30886 nonzeros\n",
      "Variable types: 0 continuous, 18167 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 5.405622e+05, 6063 iterations, 2.41 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 540562.155    0    1 84732.7904 540562.155   538%     -    4s\n",
      "H    0     0                    536223.53594 540562.155  0.81%     -    4s\n",
      "H    0     0                    538876.81691 540562.155  0.31%     -    4s\n",
      "H    0     0                    539928.53726 540562.155  0.12%     -    4s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "  MIR: 1\n",
      "\n",
      "Explored 1 nodes (6063 simplex iterations) in 4.37 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 4: 539929 538877 536224 84732.8 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.399285372563e+05, best bound 5.399285372563e+05, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "#cost minimisation model - seasonal energy constraint\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "I=range(len(df_expanded_sum))\n",
    "E=range(4)\n",
    "Z=range(len(demand_const.columns))\n",
    "S=range(2)\n",
    "cost_max=100000\n",
    "m=gp.Model()\n",
    "x = [[m.addVar(vtype=GRB.INTEGER) for e in E] for i in I] #binary variables\n",
    "for i in I:\n",
    "    m.addConstr(((x[i][0]+x[i][1]+x[i][2])*0.8+x[i][3]*0.02) <= loc_area[i])\n",
    "for z in Z:\n",
    "    for s in S:\n",
    "        m.addConstr(gp.quicksum((energy_array_seasonal[i][0][s]*x[i][0]+energy_array_seasonal[i][1][s]*x[i][1]+energy_array_seasonal[i][2][s]*x[i][2]+energy_array_seasonal[i][3][s]*x[i][3])*loc_zones_array[i][z] for i in I) <=demand_const_array[z][s])      \n",
    "\n",
    "m.addConstr(gp.quicksum(v_cost[i]*x[i][0] + n_cost[i]*x[i][1] + e_cost[i]*x[i][2] + s_cost[i]*x[i][3] for i in I)<=cost_max)        \n",
    "m.setObjective(gp.quicksum(v_NPV[i] * x[i][0]*mask_array[i]+n_NPV[i]*x[i][1]*mask_array[i]+e_NPV[i]*x[i][2]*mask_array[i]+s_NPV[i]*x[i][3]*mask_array[i] for i in I), GRB.MAXIMIZE)\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_15356/112223275.py:27: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  solution_gdf.to_file('solution_Initial.shp')\n"
     ]
    }
   ],
   "source": [
    "#append model results (location of turbines) to coordinates\n",
    "\n",
    "solution_df=df_expanded_sum.copy()\n",
    "vars=m.getVars()\n",
    "Vestas_Location=np.array([])\n",
    "Nordex_Location=np.array([])\n",
    "Enercon_Location=np.array([])\n",
    "SolarPV_Location=np.array([])\n",
    "for v in range(m.NumVars):\n",
    "    if v % 4 == 0:\n",
    "        Vestas_Location=np.append(Vestas_Location,vars[v].x)\n",
    "    else:\n",
    "        if v % 4 == 1:\n",
    "            Nordex_Location=np.append(Nordex_Location,vars[v].x)\n",
    "        else:\n",
    "            if v % 4 == 2:\n",
    "                Enercon_Location=np.append(Enercon_Location,vars[v].x)\n",
    "            else:\n",
    "                SolarPV_Location=np.append(SolarPV_Location,vars[v].x)\n",
    "            \n",
    "solution_df['Vestas_Location']=pd.Series(Vestas_Location)\n",
    "solution_df['Nordex_Location']=pd.Series(Nordex_Location)\n",
    "solution_df['Enercon_Location']=pd.Series(Enercon_Location)\n",
    "solution_df['SolarPV_Location']=pd.Series(SolarPV_Location)\n",
    "solution_df=solution_df.loc[(solution_df['Vestas_Location'] != -0) | (solution_df['Nordex_Location'] != -0) | (solution_df['Enercon_Location'] != 0) | (solution_df['SolarPV_Location'] != 0)]\n",
    "solution_gdf=geopandas.GeoDataFrame(solution_df, geometry='geometry')\n",
    "solution_gdf.to_file('solution_Initial.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_Initial = geopandas.read_file('solution_Initial.shp')\n",
    "solution_Initial.to_csv('solution_Initial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 128245 rows, 505872 columns and 22489829 nonzeros\n",
      "Model fingerprint: 0x9f915a33\n",
      "Variable types: 0 continuous, 505872 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-07, 2e+05]\n",
      "  Objective range  [1e-01, 4e+04]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 1e+05]\n",
      "Warning: Model contains large matrix coefficient range\n",
      "         Consider reformulating model or setting NumericFocus parameter\n",
      "         to avoid numerical issues.\n",
      "Found heuristic solution: objective 160527.92925\n",
      "Presolve removed 125937 rows and 498692 columns (presolve time = 5s) ...\n",
      "Presolve removed 126198 rows and 498692 columns\n",
      "Presolve time: 5.30s\n",
      "Presolved: 2047 rows, 7180 columns, 11272 nonzeros\n",
      "Variable types: 0 continuous, 7180 integer (0 binary)\n",
      "\n",
      "Root simplex log...\n",
      "\n",
      "Iteration    Objective       Primal Inf.    Dual Inf.      Time\n",
      "       0    2.4673829e+08   2.532237e+06   0.000000e+00      7s\n",
      "    2070    3.3417780e+05   0.000000e+00   0.000000e+00      7s\n",
      "\n",
      "Root relaxation: objective 3.341778e+05, 2070 iterations, 0.25 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 334177.804    0    1 160527.929 334177.804   108%     -    7s\n",
      "H    0     0                    330404.34167 334177.804  1.14%     -    7s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "  MIR: 1\n",
      "  StrongCG: 1\n",
      "\n",
      "Explored 1 nodes (2070 simplex iterations) in 8.12 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 2: 330404 160528 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 3.304043416718e+05, best bound 3.304043416718e+05, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "#cost minimisation model - hourly energy constraint\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "I=range(len(df_expanded_sum))\n",
    "E=range(4)\n",
    "Z=range(len(demand_const.columns))\n",
    "H=range(48)\n",
    "cost_max=100000\n",
    "m=gp.Model()\n",
    "x = [[m.addVar(vtype=GRB.INTEGER) for e in E] for i in I] #binary variables\n",
    "for i in I:\n",
    "    m.addConstr(((x[i][0]+x[i][1]+x[i][2])*0.8+x[i][3]*0.02) <= loc_area[i])\n",
    "for z in Z:\n",
    "    for h in H:\n",
    "        m.addConstr(gp.quicksum((energy_array[i][0][h]*x[i][0]+energy_array[i][1][h]*x[i][1]+energy_array[i][2][h]*x[i][2]+energy_array[i][3][h]*x[i][3])*loc_zones_array[i][z] for i in I) <=demand_const_array_h[z][h])      \n",
    "\n",
    "m.addConstr(gp.quicksum(v_cost[i]*x[i][0] + n_cost[i]*x[i][1] + e_cost[i]*x[i][2] + s_cost[i]*x[i][3] for i in I)<=cost_max)        \n",
    "m.setObjective(gp.quicksum(v_NPV[i] * x[i][0]*mask_array[i]+n_NPV[i]*x[i][1]*mask_array[i]+e_NPV[i]*x[i][2]*mask_array[i]+s_NPV[i]*x[i][3]*mask_array[i] for i in I), GRB.MAXIMIZE)\n",
    "m.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 126543 rows, 505872 columns and 1998218 nonzeros\n",
      "Model fingerprint: 0xc7a28eeb\n",
      "Variable types: 0 continuous, 505872 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-02, 2e+05]\n",
      "  Objective range  [1e-02, 2e+05]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 5e+05]\n",
      "Found heuristic solution: objective 45593.144900\n",
      "Presolve removed 106744 rows and 439786 columns\n",
      "Presolve time: 1.35s\n",
      "Presolved: 19799 rows, 66086 columns, 108384 nonzeros\n",
      "Variable types: 0 continuous, 66086 integer (16 binary)\n",
      "\n",
      "Deterministic concurrent LP optimizer: primal and dual simplex\n",
      "Showing first log only...\n",
      "\n",
      "Concurrent spin time: 0.00s\n",
      "\n",
      "Solved with primal simplex\n",
      "\n",
      "Root relaxation: objective 8.146577e+05, 1 iterations, 0.15 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 814657.675    0    1 45593.1449 814657.675  1687%     -    1s\n",
      "H    0     0                    811991.33279 814657.675  0.33%     -    1s\n",
      "H    0     0                    813382.52088 814657.675  0.16%     -    2s\n",
      "     0     0 814082.166    0    3 813382.521 814082.166  0.09%     -    2s\n",
      "     0     0 814082.166    0    1 813382.521 814082.166  0.09%     -    2s\n",
      "     0     0 814082.166    0    3 813382.521 814082.166  0.09%     -    2s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 6\n",
      "  MIR: 3\n",
      "  StrongCG: 1\n",
      "\n",
      "Explored 1 nodes (9 simplex iterations) in 2.57 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 813383 811991 45593.1 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 8.133825208805e+05, best bound 8.134448940008e+05, gap 0.0077%\n"
     ]
    }
   ],
   "source": [
    "#cost minimisation model - no country constraint\n",
    "I=range(len(df_expanded_sum))\n",
    "E=range(4)\n",
    "Z=range(len(demand_const.columns))\n",
    "S=range(2)\n",
    "cost_max=100000\n",
    "m1=gp.Model()\n",
    "x = [[m1.addVar(vtype=GRB.INTEGER) for e in E] for i in I] #binary variables\n",
    "for i in I:\n",
    "    m1.addConstr(((x[i][0]+x[i][1]+x[i][2])*0.8+x[i][3]*0.02) <= loc_area[i])\n",
    "for z in Z:\n",
    "    for s in S:\n",
    "        m1.addConstr(gp.quicksum((energy_array_seasonal[i][0][s]*x[i][0]+energy_array_seasonal[i][1][s]*x[i][1]+energy_array_seasonal[i][2][s]*x[i][2]+energy_array_seasonal[i][3][s]*x[i][3])*loc_zones_array[i][z] for i in I) <=demand_const_array[z][s])      \n",
    "\n",
    "m1.addConstr(gp.quicksum(v_cost[i]*x[i][0] + n_cost[i]*x[i][1] + e_cost[i]*x[i][2] + s_cost[i]*x[i][3] for i in I)<=cost_max)        \n",
    "m1.setObjective(gp.quicksum(v_NPV[i] * x[i][0]+n_NPV[i]*x[i][1]+e_NPV[i]*x[i][2]+s_NPV[i]*x[i][3] for i in I), GRB.MAXIMIZE)\n",
    "m1.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_15356/1653935046.py:27: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  solution_gdf.to_file('solution_NoCountry.shp')\n"
     ]
    }
   ],
   "source": [
    "#append model results (location of turbines) to coordinates\n",
    "\n",
    "solution_df=df_expanded_sum.copy()\n",
    "vars=m1.getVars()\n",
    "Vestas_Location=np.array([])\n",
    "Nordex_Location=np.array([])\n",
    "Enercon_Location=np.array([])\n",
    "SolarPV_Location=np.array([])\n",
    "for v in range(m1.NumVars):\n",
    "    if v % 4 == 0:\n",
    "        Vestas_Location=np.append(Vestas_Location,vars[v].x)\n",
    "    else:\n",
    "        if v % 4 == 1:\n",
    "            Nordex_Location=np.append(Nordex_Location,vars[v].x)\n",
    "        else:\n",
    "            if v % 4 == 2:\n",
    "                Enercon_Location=np.append(Enercon_Location,vars[v].x)\n",
    "            else:\n",
    "                SolarPV_Location=np.append(SolarPV_Location,vars[v].x)\n",
    "            \n",
    "solution_df['Vestas_Location']=pd.Series(Vestas_Location)\n",
    "solution_df['Nordex_Location']=pd.Series(Nordex_Location)\n",
    "solution_df['Enercon_Location']=pd.Series(Enercon_Location)\n",
    "solution_df['SolarPV_Location']=pd.Series(SolarPV_Location)\n",
    "solution_df=solution_df.loc[(solution_df['Vestas_Location'] != -0) | (solution_df['Nordex_Location'] != -0) | (solution_df['Enercon_Location'] != 0) | (solution_df['SolarPV_Location'] != 0)]\n",
    "solution_gdf=geopandas.GeoDataFrame(solution_df, geometry='geometry')\n",
    "solution_gdf.to_file('solution_NoCountry.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_NoCountry = geopandas.read_file('solution_NoCountry.shp')\n",
    "solution_NoCountry.to_csv('solution_NoCountry.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 126543 rows, 505872 columns and 1998218 nonzeros\n",
      "Model fingerprint: 0xd2964356\n",
      "Variable types: 0 continuous, 505872 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-02, 2e+05]\n",
      "  Objective range  [1e-02, 2e+04]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 5e+05]\n",
      "Found heuristic solution: objective 11589.455243\n",
      "Presolve removed 123186 rows and 487705 columns\n",
      "Presolve time: 0.68s\n",
      "Presolved: 3357 rows, 18167 columns, 25458 nonzeros\n",
      "Variable types: 0 continuous, 18167 integer (88 binary)\n",
      "\n",
      "Root relaxation: objective 5.381759e+04, 3724 iterations, 0.89 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 53817.5856    0    1 11589.4552 53817.5856   364%     -    1s\n",
      "H    0     0                    50540.678209 53817.5856  6.48%     -    1s\n",
      "H    0     0                    53305.365737 53817.5856  0.96%     -    1s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "  MIR: 1\n",
      "  StrongCG: 1\n",
      "\n",
      "Explored 1 nodes (3724 simplex iterations) in 2.02 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 53305.4 50540.7 11589.5 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.330536573722e+04, best bound 5.330536573722e+04, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "#cost minimisation model - different costs\n",
    "\n",
    "I=range(len(df_expanded_sum))\n",
    "E=range(4)\n",
    "Z=range(len(demand_const.columns))\n",
    "S=range(2)\n",
    "cost_max=10000\n",
    "m2=gp.Model()\n",
    "x = [[m2.addVar(vtype=GRB.INTEGER) for e in E] for i in I] #binary variables\n",
    "for i in I:\n",
    "    m2.addConstr(((x[i][0]+x[i][1]+x[i][2])*0.8+x[i][3]*0.02) <= loc_area[i])\n",
    "for z in Z:\n",
    "    for s in S:\n",
    "        m2.addConstr(gp.quicksum((energy_array_seasonal[i][0][s]*x[i][0]+energy_array_seasonal[i][1][s]*x[i][1]+energy_array_seasonal[i][2][s]*x[i][2]+energy_array_seasonal[i][3][s]*x[i][3])*loc_zones_array[i][z] for i in I) <=demand_const_array[z][s])      \n",
    "\n",
    "m2.addConstr(gp.quicksum(v_cost[i]*x[i][0] + n_cost[i]*x[i][1] + e_cost[i]*x[i][2] + s_cost[i]*x[i][3] for i in I)<=cost_max)        \n",
    "m2.setObjective(gp.quicksum(v_NPV[i] * x[i][0]*mask_array[i]+n_NPV[i]*x[i][1]*mask_array[i]+e_NPV[i]*x[i][2]*mask_array[i]+s_NPV[i]*x[i][3]*mask_array[i] for i in I), GRB.MAXIMIZE)\n",
    "m2.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_15356/1716620687.py:27: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  solution_gdf.to_file('solution_10K.shp')\n"
     ]
    }
   ],
   "source": [
    "#append model results (location of turbines) to coordinates\n",
    "\n",
    "solution_df=df_expanded_sum.copy()\n",
    "vars=m2.getVars()\n",
    "Vestas_Location=np.array([])\n",
    "Nordex_Location=np.array([])\n",
    "Enercon_Location=np.array([])\n",
    "SolarPV_Location=np.array([])\n",
    "for v in range(m2.NumVars):\n",
    "    if v % 4 == 0:\n",
    "        Vestas_Location=np.append(Vestas_Location,vars[v].x)\n",
    "    else:\n",
    "        if v % 4 == 1:\n",
    "            Nordex_Location=np.append(Nordex_Location,vars[v].x)\n",
    "        else:\n",
    "            if v % 4 == 2:\n",
    "                Enercon_Location=np.append(Enercon_Location,vars[v].x)\n",
    "            else:\n",
    "                SolarPV_Location=np.append(SolarPV_Location,vars[v].x)\n",
    "            \n",
    "solution_df['Vestas_Location']=pd.Series(Vestas_Location)\n",
    "solution_df['Nordex_Location']=pd.Series(Nordex_Location)\n",
    "solution_df['Enercon_Location']=pd.Series(Enercon_Location)\n",
    "solution_df['SolarPV_Location']=pd.Series(SolarPV_Location)\n",
    "solution_df=solution_df.loc[(solution_df['Vestas_Location'] != -0) | (solution_df['Nordex_Location'] != -0) | (solution_df['Enercon_Location'] != 0) | (solution_df['SolarPV_Location'] != 0)]\n",
    "solution_gdf=geopandas.GeoDataFrame(solution_df, geometry='geometry')\n",
    "solution_gdf.to_file('solution_10K.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_10K = geopandas.read_file('solution_10K.shp')\n",
    "solution_10K.to_csv('solution_10K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 126543 rows, 505872 columns and 1998218 nonzeros\n",
      "Model fingerprint: 0x6edc62ba\n",
      "Variable types: 0 continuous, 505872 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-02, 2e+05]\n",
      "  Objective range  [1e-02, 2e+04]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 5e+05]\n",
      "Found heuristic solution: objective 58174.143653\n",
      "Presolve removed 120938 rows and 487705 columns\n",
      "Presolve time: 0.63s\n",
      "Presolved: 5605 rows, 18167 columns, 30095 nonzeros\n",
      "Variable types: 0 continuous, 18167 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 2.702811e+05, 5710 iterations, 1.71 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 270281.077    0    1 58174.1437 270281.077   365%     -    2s\n",
      "H    0     0                    266889.36623 270281.077  1.27%     -    2s\n",
      "H    0     0                    268586.44682 270281.077  0.63%     -    2s\n",
      "     0     0 269130.540    0    2 268586.447 269130.540  0.20%     -    2s\n",
      "     0     0 269130.540    0    1 268586.447 269130.540  0.20%     -    2s\n",
      "     0     0 269130.540    0    2 268586.447 269130.540  0.20%     -    2s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 5\n",
      "  MIR: 4\n",
      "  StrongCG: 3\n",
      "\n",
      "Explored 1 nodes (5715 simplex iterations) in 3.00 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 268586 266889 58174.1 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.685864468247e+05, best bound 2.685951197746e+05, gap 0.0032%\n"
     ]
    }
   ],
   "source": [
    "#cost minimisation model - different costs\n",
    "\n",
    "I=range(len(df_expanded_sum))\n",
    "E=range(4)\n",
    "Z=range(len(demand_const.columns))\n",
    "S=range(2)\n",
    "cost_max=50000\n",
    "m4=gp.Model()\n",
    "x = [[m4.addVar(vtype=GRB.INTEGER) for e in E] for i in I] #binary variables\n",
    "for i in I:\n",
    "    m4.addConstr(((x[i][0]+x[i][1]+x[i][2])*0.8+x[i][3]*0.02) <= loc_area[i])\n",
    "for z in Z:\n",
    "    for s in S:\n",
    "        m4.addConstr(gp.quicksum((energy_array_seasonal[i][0][s]*x[i][0]+energy_array_seasonal[i][1][s]*x[i][1]+energy_array_seasonal[i][2][s]*x[i][2]+energy_array_seasonal[i][3][s]*x[i][3])*loc_zones_array[i][z] for i in I) <=demand_const_array[z][s])      \n",
    "\n",
    "m4.addConstr(gp.quicksum(v_cost[i]*x[i][0] + n_cost[i]*x[i][1] + e_cost[i]*x[i][2] + s_cost[i]*x[i][3] for i in I)<=cost_max)        \n",
    "m4.setObjective(gp.quicksum(v_NPV[i] * x[i][0]*mask_array[i]+n_NPV[i]*x[i][1]*mask_array[i]+e_NPV[i]*x[i][2]*mask_array[i]+s_NPV[i]*x[i][3]*mask_array[i] for i in I), GRB.MAXIMIZE)\n",
    "m4.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_15356/307477105.py:27: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  solution_gdf.to_file('solution_50K.shp')\n"
     ]
    }
   ],
   "source": [
    "#append model results (location of turbines) to coordinates\n",
    "\n",
    "solution_df=df_expanded_sum.copy()\n",
    "vars=m4.getVars()\n",
    "Vestas_Location=np.array([])\n",
    "Nordex_Location=np.array([])\n",
    "Enercon_Location=np.array([])\n",
    "SolarPV_Location=np.array([])\n",
    "for v in range(m4.NumVars):\n",
    "    if v % 4 == 0:\n",
    "        Vestas_Location=np.append(Vestas_Location,vars[v].x)\n",
    "    else:\n",
    "        if v % 4 == 1:\n",
    "            Nordex_Location=np.append(Nordex_Location,vars[v].x)\n",
    "        else:\n",
    "            if v % 4 == 2:\n",
    "                Enercon_Location=np.append(Enercon_Location,vars[v].x)\n",
    "            else:\n",
    "                SolarPV_Location=np.append(SolarPV_Location,vars[v].x)\n",
    "            \n",
    "solution_df['Vestas_Location']=pd.Series(Vestas_Location)\n",
    "solution_df['Nordex_Location']=pd.Series(Nordex_Location)\n",
    "solution_df['Enercon_Location']=pd.Series(Enercon_Location)\n",
    "solution_df['SolarPV_Location']=pd.Series(SolarPV_Location)\n",
    "solution_df=solution_df.loc[(solution_df['Vestas_Location'] != -0) | (solution_df['Nordex_Location'] != -0) | (solution_df['Enercon_Location'] != 0) | (solution_df['SolarPV_Location'] != 0)]\n",
    "solution_gdf=geopandas.GeoDataFrame(solution_df, geometry='geometry')\n",
    "solution_gdf.to_file('solution_50K.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_50K = geopandas.read_file('solution_50K.shp')\n",
    "solution_50K.to_csv('solution_50K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 126543 rows, 505872 columns and 1998218 nonzeros\n",
      "Model fingerprint: 0x6b3e1d69\n",
      "Variable types: 0 continuous, 505872 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-02, 2e+05]\n",
      "  Objective range  [1e-02, 2e+04]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 5e+05]\n",
      "Found heuristic solution: objective 99478.949107\n",
      "Presolve removed 120331 rows and 487705 columns\n",
      "Presolve time: 0.65s\n",
      "Presolved: 6212 rows, 18167 columns, 31358 nonzeros\n",
      "Variable types: 0 continuous, 18167 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 1.081522e+06, 6261 iterations, 1.90 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1081522.03    0    1 99478.9491 1081522.03   987%     -    2s\n",
      "H    0     0                    1078040.3395 1081522.03  0.32%     -    2s\n",
      "H    0     0                    1080746.4073 1081522.03  0.07%     -    2s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 3\n",
      "  MIR: 1\n",
      "  StrongCG: 1\n",
      "\n",
      "Explored 1 nodes (6261 simplex iterations) in 3.13 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 1.08075e+06 1.07804e+06 99478.9 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.080746407339e+06, best bound 1.080746407339e+06, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "#cost minimisation model - different costs\n",
    "\n",
    "I=range(len(df_expanded_sum))\n",
    "E=range(4)\n",
    "Z=range(len(demand_const.columns))\n",
    "S=range(2)\n",
    "cost_max=200000\n",
    "m5=gp.Model()\n",
    "x = [[m5.addVar(vtype=GRB.INTEGER) for e in E] for i in I] #binary variables\n",
    "for i in I:\n",
    "    m5.addConstr(((x[i][0]+x[i][1]+x[i][2])*0.8+x[i][3]*0.02) <= loc_area[i])\n",
    "for z in Z:\n",
    "    for s in S:\n",
    "        m5.addConstr(gp.quicksum((energy_array_seasonal[i][0][s]*x[i][0]+energy_array_seasonal[i][1][s]*x[i][1]+energy_array_seasonal[i][2][s]*x[i][2]+energy_array_seasonal[i][3][s]*x[i][3])*loc_zones_array[i][z] for i in I) <=demand_const_array[z][s])      \n",
    "\n",
    "m5.addConstr(gp.quicksum(v_cost[i]*x[i][0] + n_cost[i]*x[i][1] + e_cost[i]*x[i][2] + s_cost[i]*x[i][3] for i in I)<=cost_max)        \n",
    "m5.setObjective(gp.quicksum(v_NPV[i] * x[i][0]*mask_array[i]+n_NPV[i]*x[i][1]*mask_array[i]+e_NPV[i]*x[i][2]*mask_array[i]+s_NPV[i]*x[i][3]*mask_array[i] for i in I), GRB.MAXIMIZE)\n",
    "m5.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_15356/1856312979.py:27: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  solution_gdf.to_file('solution_200K.shp')\n"
     ]
    }
   ],
   "source": [
    "#append model results (location of turbines) to coordinates\n",
    "\n",
    "solution_df=df_expanded_sum.copy()\n",
    "vars=m5.getVars()\n",
    "Vestas_Location=np.array([])\n",
    "Nordex_Location=np.array([])\n",
    "Enercon_Location=np.array([])\n",
    "SolarPV_Location=np.array([])\n",
    "for v in range(m5.NumVars):\n",
    "    if v % 4 == 0:\n",
    "        Vestas_Location=np.append(Vestas_Location,vars[v].x)\n",
    "    else:\n",
    "        if v % 4 == 1:\n",
    "            Nordex_Location=np.append(Nordex_Location,vars[v].x)\n",
    "        else:\n",
    "            if v % 4 == 2:\n",
    "                Enercon_Location=np.append(Enercon_Location,vars[v].x)\n",
    "            else:\n",
    "                SolarPV_Location=np.append(SolarPV_Location,vars[v].x)\n",
    "            \n",
    "solution_df['Vestas_Location']=pd.Series(Vestas_Location)\n",
    "solution_df['Nordex_Location']=pd.Series(Nordex_Location)\n",
    "solution_df['Enercon_Location']=pd.Series(Enercon_Location)\n",
    "solution_df['SolarPV_Location']=pd.Series(SolarPV_Location)\n",
    "solution_df=solution_df.loc[(solution_df['Vestas_Location'] != -0) | (solution_df['Nordex_Location'] != -0) | (solution_df['Enercon_Location'] != 0) | (solution_df['SolarPV_Location'] != 0)]\n",
    "solution_gdf=geopandas.GeoDataFrame(solution_df, geometry='geometry')\n",
    "solution_gdf.to_file('solution_200K.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_200K = geopandas.read_file('solution_200K.shp')\n",
    "solution_200K.to_csv('solution_200K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 126543 rows, 505872 columns and 1998218 nonzeros\n",
      "Model fingerprint: 0xf44902bb\n",
      "Variable types: 0 continuous, 505872 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-02, 2e+05]\n",
      "  Objective range  [1e-02, 2e+04]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 5e+05]\n",
      "Found heuristic solution: objective 137642.50145\n",
      "Presolve removed 120126 rows and 487705 columns\n",
      "Presolve time: 0.73s\n",
      "Presolved: 6417 rows, 18167 columns, 49956 nonzeros\n",
      "Variable types: 0 continuous, 18167 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 1.404570e+06, 6458 iterations, 2.02 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1404569.69    0    1 137642.501 1404569.69   920%     -    3s\n",
      "H    0     0                    1403217.0701 1404569.69  0.10%     -    3s\n",
      "H    0     0                    1404460.7081 1404569.69  0.01%     -    3s\n",
      "\n",
      "Explored 1 nodes (6458 simplex iterations) in 3.29 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 1.40446e+06 1.40322e+06 137643 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.404460708118e+06, best bound 1.404569685040e+06, gap 0.0078%\n"
     ]
    }
   ],
   "source": [
    "#cost minimisation model - different costs\n",
    "\n",
    "I=range(len(df_expanded_sum))\n",
    "E=range(4)\n",
    "Z=range(len(demand_const.columns))\n",
    "S=range(2)\n",
    "cost_max=500000\n",
    "m6=gp.Model()\n",
    "x = [[m6.addVar(vtype=GRB.INTEGER) for e in E] for i in I] #binary variables\n",
    "for i in I:\n",
    "    m6.addConstr(((x[i][0]+x[i][1]+x[i][2])*0.8+x[i][3]*0.02) <= loc_area[i])\n",
    "for z in Z:\n",
    "    for s in S:\n",
    "        m6.addConstr(gp.quicksum((energy_array_seasonal[i][0][s]*x[i][0]+energy_array_seasonal[i][1][s]*x[i][1]+energy_array_seasonal[i][2][s]*x[i][2]+energy_array_seasonal[i][3][s]*x[i][3])*loc_zones_array[i][z] for i in I) <=demand_const_array[z][s])      \n",
    "\n",
    "m6.addConstr(gp.quicksum(v_cost[i]*x[i][0] + n_cost[i]*x[i][1] + e_cost[i]*x[i][2] + s_cost[i]*x[i][3] for i in I)<=cost_max)        \n",
    "m6.setObjective(gp.quicksum(v_NPV[i] * x[i][0]*mask_array[i]+n_NPV[i]*x[i][1]*mask_array[i]+e_NPV[i]*x[i][2]*mask_array[i]+s_NPV[i]*x[i][3]*mask_array[i] for i in I), GRB.MAXIMIZE)\n",
    "m6.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_15356/1073804603.py:27: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  solution_gdf.to_file('solution_500k.shp')\n"
     ]
    }
   ],
   "source": [
    "#append model results (location of turbines) to coordinates\n",
    "\n",
    "solution_df=df_expanded_sum.copy()\n",
    "vars=m6.getVars()\n",
    "Vestas_Location=np.array([])\n",
    "Nordex_Location=np.array([])\n",
    "Enercon_Location=np.array([])\n",
    "SolarPV_Location=np.array([])\n",
    "for v in range(m6.NumVars):\n",
    "    if v % 4 == 0:\n",
    "        Vestas_Location=np.append(Vestas_Location,vars[v].x)\n",
    "    else:\n",
    "        if v % 4 == 1:\n",
    "            Nordex_Location=np.append(Nordex_Location,vars[v].x)\n",
    "        else:\n",
    "            if v % 4 == 2:\n",
    "                Enercon_Location=np.append(Enercon_Location,vars[v].x)\n",
    "            else:\n",
    "                SolarPV_Location=np.append(SolarPV_Location,vars[v].x)\n",
    "            \n",
    "solution_df['Vestas_Location']=pd.Series(Vestas_Location)\n",
    "solution_df['Nordex_Location']=pd.Series(Nordex_Location)\n",
    "solution_df['Enercon_Location']=pd.Series(Enercon_Location)\n",
    "solution_df['SolarPV_Location']=pd.Series(SolarPV_Location)\n",
    "solution_df=solution_df.loc[(solution_df['Vestas_Location'] != -0) | (solution_df['Nordex_Location'] != -0) | (solution_df['Enercon_Location'] != 0) | (solution_df['SolarPV_Location'] != 0)]\n",
    "solution_gdf=geopandas.GeoDataFrame(solution_df, geometry='geometry')\n",
    "solution_gdf.to_file('solution_500k.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_500K = geopandas.read_file('solution_500K.shp')\n",
    "solution_500K.to_csv('solution_500K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 126543 rows, 505872 columns and 1998218 nonzeros\n",
      "Model fingerprint: 0x5ec884b1\n",
      "Variable types: 0 continuous, 505872 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-02, 2e+05]\n",
      "  Objective range  [1e-02, 2e+04]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 1e+06]\n",
      "Found heuristic solution: objective 206364.03754\n",
      "Presolve removed 120008 rows and 487705 columns\n",
      "Presolve time: 0.76s\n",
      "Presolved: 6535 rows, 18167 columns, 50205 nonzeros\n",
      "Variable types: 0 continuous, 18167 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 1.404570e+06, 6606 iterations, 2.01 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 1404569.69    0    1 206364.038 1404569.69   581%     -    3s\n",
      "H    0     0                    1403217.0701 1404569.69  0.10%     -    3s\n",
      "H    0     0                    1404460.7081 1404569.69  0.01%     -    3s\n",
      "\n",
      "Explored 1 nodes (6606 simplex iterations) in 3.21 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 1.40446e+06 1.40322e+06 206364 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.404460708118e+06, best bound 1.404569685040e+06, gap 0.0078%\n"
     ]
    }
   ],
   "source": [
    "#cost minimisation model - different costs\n",
    "\n",
    "I=range(len(df_expanded_sum))\n",
    "E=range(4)\n",
    "Z=range(len(demand_const.columns))\n",
    "S=range(2)\n",
    "cost_max=1000000\n",
    "m7=gp.Model()\n",
    "x = [[m7.addVar(vtype=GRB.INTEGER) for e in E] for i in I] #binary variables\n",
    "for i in I:\n",
    "    m7.addConstr(((x[i][0]+x[i][1]+x[i][2])*0.8+x[i][3]*0.02) <= loc_area[i])\n",
    "for z in Z:\n",
    "    for s in S:\n",
    "        m7.addConstr(gp.quicksum((energy_array_seasonal[i][0][s]*x[i][0]+energy_array_seasonal[i][1][s]*x[i][1]+energy_array_seasonal[i][2][s]*x[i][2]+energy_array_seasonal[i][3][s]*x[i][3])*loc_zones_array[i][z] for i in I) <=demand_const_array[z][s])      \n",
    "\n",
    "m7.addConstr(gp.quicksum(v_cost[i]*x[i][0] + n_cost[i]*x[i][1] + e_cost[i]*x[i][2] + s_cost[i]*x[i][3] for i in I)<=cost_max)        \n",
    "m7.setObjective(gp.quicksum(v_NPV[i] * x[i][0]*mask_array[i]+n_NPV[i]*x[i][1]*mask_array[i]+e_NPV[i]*x[i][2]*mask_array[i]+s_NPV[i]*x[i][3]*mask_array[i] for i in I), GRB.MAXIMIZE)\n",
    "m7.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_15356/3369593645.py:27: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  solution_gdf.to_file('solution_1M.shp')\n"
     ]
    }
   ],
   "source": [
    "#append model results (location of turbines) to coordinates\n",
    "\n",
    "solution_df=df_expanded_sum.copy()\n",
    "vars=m7.getVars()\n",
    "Vestas_Location=np.array([])\n",
    "Nordex_Location=np.array([])\n",
    "Enercon_Location=np.array([])\n",
    "SolarPV_Location=np.array([])\n",
    "for v in range(m7.NumVars):\n",
    "    if v % 4 == 0:\n",
    "        Vestas_Location=np.append(Vestas_Location,vars[v].x)\n",
    "    else:\n",
    "        if v % 4 == 1:\n",
    "            Nordex_Location=np.append(Nordex_Location,vars[v].x)\n",
    "        else:\n",
    "            if v % 4 == 2:\n",
    "                Enercon_Location=np.append(Enercon_Location,vars[v].x)\n",
    "            else:\n",
    "                SolarPV_Location=np.append(SolarPV_Location,vars[v].x)\n",
    "            \n",
    "solution_df['Vestas_Location']=pd.Series(Vestas_Location)\n",
    "solution_df['Nordex_Location']=pd.Series(Nordex_Location)\n",
    "solution_df['Enercon_Location']=pd.Series(Enercon_Location)\n",
    "solution_df['SolarPV_Location']=pd.Series(SolarPV_Location)\n",
    "solution_df=solution_df.loc[(solution_df['Vestas_Location'] != -0) | (solution_df['Nordex_Location'] != -0) | (solution_df['Enercon_Location'] != 0) | (solution_df['SolarPV_Location'] != 0)]\n",
    "solution_gdf=geopandas.GeoDataFrame(solution_df, geometry='geometry')\n",
    "solution_gdf.to_file('solution_1M.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_1M = geopandas.read_file('solution_1M.shp')\n",
    "solution_1M.to_csv('solution_1M.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 126543 rows, 505872 columns and 505872 nonzeros\n",
      "Model fingerprint: 0x25a0e76b\n",
      "Variable types: 0 continuous, 505872 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [4e-02, 2e+05]\n",
      "  Objective range  [1e-02, 2e+04]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 5e+05]\n",
      "Found heuristic solution: objective 33521.996726\n",
      "Presolve removed 126542 rows and 499081 columns\n",
      "Presolve time: 0.30s\n",
      "Presolved: 1 rows, 6791 columns, 6791 nonzeros\n",
      "Variable types: 0 continuous, 6791 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 5.102765e+05, 1 iterations, 0.00 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 510276.521    0    1 33521.9967 510276.521  1422%     -    0s\n",
      "H    0     0                    509339.41423 510276.521  0.18%     -    0s\n",
      "H    0     0                    509606.22883 510276.521  0.13%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Gomory: 1\n",
      "  MIR: 1\n",
      "  StrongCG: 1\n",
      "\n",
      "Explored 1 nodes (1 simplex iterations) in 0.57 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 509606 509339 33522 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 5.096062288272e+05, best bound 5.096062288272e+05, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "#cost minimisation model - different equipment\n",
    "\n",
    "I=range(len(df_expanded_sum))\n",
    "E=range(4)\n",
    "Z=range(len(demand_const.columns))\n",
    "S=range(2)\n",
    "cost_max=100000\n",
    "m3=gp.Model()\n",
    "x = [[m3.addVar(vtype=GRB.INTEGER) for e in E] for i in I] #binary variables\n",
    "for i in I:\n",
    "    m3.addConstr(((x[i][1])*0.8) <= loc_area[i])\n",
    "for z in Z:\n",
    "    for s in S:\n",
    "        m3.addConstr(gp.quicksum((energy_array_seasonal[i][1][s]*x[i][1])*loc_zones_array[i][z] for i in I) <=demand_const_array[z][s])      \n",
    "\n",
    "m3.addConstr(gp.quicksum( n_cost[i]*x[i][1] for i in I)<=cost_max)        \n",
    "m3.setObjective(gp.quicksum(n_NPV[i]*x[i][1]*mask_array[i] for i in I), GRB.MAXIMIZE)\n",
    "m3.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_15356/2932157339.py:27: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  solution_gdf.to_file('solution_NordexOnly.shp')\n"
     ]
    }
   ],
   "source": [
    "#append model results (location of turbines) to coordinates\n",
    "\n",
    "solution_df=df_expanded_sum.copy()\n",
    "vars=m3.getVars()\n",
    "Vestas_Location=np.array([])\n",
    "Nordex_Location=np.array([])\n",
    "Enercon_Location=np.array([])\n",
    "SolarPV_Location=np.array([])\n",
    "for v in range(m3.NumVars):\n",
    "    if v % 4 == 0:\n",
    "        Vestas_Location=np.append(Vestas_Location,vars[v].x)\n",
    "    else:\n",
    "        if v % 4 == 1:\n",
    "            Nordex_Location=np.append(Nordex_Location,vars[v].x)\n",
    "        else:\n",
    "            if v % 4 == 2:\n",
    "                Enercon_Location=np.append(Enercon_Location,vars[v].x)\n",
    "            else:\n",
    "                SolarPV_Location=np.append(SolarPV_Location,vars[v].x)\n",
    "            \n",
    "solution_df['Vestas_Location']=pd.Series(Vestas_Location)\n",
    "solution_df['Nordex_Location']=pd.Series(Nordex_Location)\n",
    "solution_df['Enercon_Location']=pd.Series(Enercon_Location)\n",
    "solution_df['SolarPV_Location']=pd.Series(SolarPV_Location)\n",
    "solution_df=solution_df.loc[(solution_df['Vestas_Location'] != -0) | (solution_df['Nordex_Location'] != -0) | (solution_df['Enercon_Location'] != 0) | (solution_df['SolarPV_Location'] != 0)]\n",
    "solution_gdf=geopandas.GeoDataFrame(solution_df, geometry='geometry')\n",
    "solution_gdf.to_file('solution_NordexOnly.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution_NordexOnly = geopandas.read_file('solution_NordexOnly.shp')\n",
    "solution_NordexOnly.to_csv('solution_NordexOnly.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 126543 rows, 505872 columns and 480602 nonzeros\n",
      "Model fingerprint: 0x0deba520\n",
      "Variable types: 0 continuous, 505872 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-02, 2e+05]\n",
      "  Objective range  [3e+02, 2e+04]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 5e+05]\n",
      "Found heuristic solution: objective -0.0000000\n",
      "\n",
      "Explored 0 nodes (0 simplex iterations) in 0.14 seconds\n",
      "Thread count was 1 (of 8 available processors)\n",
      "\n",
      "Solution count 1: -0 \n",
      "No other solutions better than -0\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective -0.000000000000e+00, best bound -0.000000000000e+00, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "#cost minimisation model - different equipment, Solar PV\n",
    "\n",
    "I=range(len(df_expanded_sum))\n",
    "E=range(4)\n",
    "Z=range(len(demand_const.columns))\n",
    "S=range(2)\n",
    "cost_max=100000\n",
    "m8=gp.Model()\n",
    "x = [[m8.addVar(vtype=GRB.INTEGER) for e in E] for i in I] #binary variables\n",
    "for i in I:\n",
    "    m8.addConstr(((x[i][3])*0.02) <= loc_area[i])\n",
    "for z in Z:\n",
    "    for s in S:\n",
    "        m8.addConstr(gp.quicksum((energy_array_seasonal[i][3][s]*x[i][3])*loc_zones_array[i][z] for i in I) <=demand_const_array[z][s])      \n",
    "\n",
    "m8.addConstr(gp.quicksum( s_cost[i]*x[i][3] for i in I)<=cost_max)        \n",
    "m8.setObjective(gp.quicksum(s_NPV[i]*x[i][3]*mask_array[i] for i in I), GRB.MAXIMIZE)\n",
    "m8.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot write empty DataFrame to file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_15356/4258683101.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0msolution_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolution_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolution_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Vestas_Location'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msolution_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Nordex_Location'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msolution_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Enercon_Location'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msolution_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SolarPV_Location'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0msolution_gdf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGeoDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolution_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeometry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'geometry'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0msolution_gdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'solution_SolarOnly.shp'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/geo_env2/lib/python3.9/site-packages/geopandas/geodataframe.py\u001b[0m in \u001b[0;36mto_file\u001b[0;34m(self, filename, driver, schema, index, **kwargs)\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_to_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1086\u001b[0;31m         \u001b[0m_to_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1087\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1088\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_crs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_override\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/geo_env2/lib/python3.9/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36m_to_file\u001b[0;34m(df, filename, driver, schema, index, mode, crs, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mschema\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0mschema\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfer_schema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcrs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mcrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyproj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCRS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_user_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/geo_env2/lib/python3.9/site-packages/geopandas/io/file.py\u001b[0m in \u001b[0;36minfer_schema\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cannot write empty DataFrame to file.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;31m# Since https://github.com/Toblerity/Fiona/issues/446 resolution,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot write empty DataFrame to file."
     ]
    }
   ],
   "source": [
    "#append model results (location of turbines) to coordinates\n",
    "\n",
    "solution_df=df_expanded_sum.copy()\n",
    "vars=m8.getVars()\n",
    "Vestas_Location=np.array([])\n",
    "Nordex_Location=np.array([])\n",
    "Enercon_Location=np.array([])\n",
    "SolarPV_Location=np.array([])\n",
    "for v in range(m8.NumVars):\n",
    "    if v % 4 == 0:\n",
    "        Vestas_Location=np.append(Vestas_Location,vars[v].x)\n",
    "    else:\n",
    "        if v % 4 == 1:\n",
    "            Nordex_Location=np.append(Nordex_Location,vars[v].x)\n",
    "        else:\n",
    "            if v % 4 == 2:\n",
    "                Enercon_Location=np.append(Enercon_Location,vars[v].x)\n",
    "            else:\n",
    "                SolarPV_Location=np.append(SolarPV_Location,vars[v].x)\n",
    "            \n",
    "solution_df['Vestas_Location']=pd.Series(Vestas_Location)\n",
    "solution_df['Nordex_Location']=pd.Series(Nordex_Location)\n",
    "solution_df['Enercon_Location']=pd.Series(Enercon_Location)\n",
    "solution_df['SolarPV_Location']=pd.Series(SolarPV_Location)\n",
    "solution_df=solution_df.loc[(solution_df['Vestas_Location'] != -0) | (solution_df['Nordex_Location'] != -0) | (solution_df['Enercon_Location'] != 0) | (solution_df['SolarPV_Location'] != 0)]\n",
    "solution_gdf=geopandas.GeoDataFrame(solution_df, geometry='geometry')\n",
    "solution_gdf.to_file('solution_SolarOnly.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (mac64)\n",
      "Thread count: 4 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 126543 rows, 505872 columns and 505872 nonzeros\n",
      "Model fingerprint: 0x94a3db4b\n",
      "Variable types: 0 continuous, 505872 integer (0 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [3e-02, 2e+05]\n",
      "  Objective range  [1e-01, 2e+04]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [2e+00, 5e+05]\n",
      "Found heuristic solution: objective 2013.8036382\n",
      "Presolve removed 126542 rows and 505859 columns\n",
      "Presolve time: 0.26s\n",
      "Presolved: 1 rows, 13 columns, 13 nonzeros\n",
      "Found heuristic solution: objective 121273.93254\n",
      "Variable types: 0 continuous, 13 integer (0 binary)\n",
      "\n",
      "Root relaxation: objective 2.136584e+05, 1 iterations, 0.00 seconds\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0 213658.424    0    1 121273.933 213658.424  76.2%     -    0s\n",
      "H    0     0                    213518.38419 213658.424  0.07%     -    0s\n",
      "     0     0 213658.424    0    1 213518.384 213658.424  0.07%     -    0s\n",
      "\n",
      "Explored 1 nodes (1 simplex iterations) in 0.56 seconds\n",
      "Thread count was 8 (of 8 available processors)\n",
      "\n",
      "Solution count 3: 213518 121274 2013.8 \n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 2.135183841887e+05, best bound 2.135183841887e+05, gap 0.0000%\n"
     ]
    }
   ],
   "source": [
    "#cost minimisation model - different equipment, Enercon\n",
    "\n",
    "I=range(len(df_expanded_sum))\n",
    "E=range(4)\n",
    "Z=range(len(demand_const.columns))\n",
    "S=range(2)\n",
    "cost_max=100000\n",
    "m9=gp.Model()\n",
    "x = [[m9.addVar(vtype=GRB.INTEGER) for e in E] for i in I] #binary variables\n",
    "for i in I:\n",
    "    m9.addConstr(((x[i][2])*0.8) <= loc_area[i])\n",
    "for z in Z:\n",
    "    for s in S:\n",
    "        m9.addConstr(gp.quicksum((energy_array_seasonal[i][2][s]*x[i][2])*loc_zones_array[i][z] for i in I) <=demand_const_array[z][s])      \n",
    "\n",
    "m9.addConstr(gp.quicksum( e_cost[i]*x[i][2] for i in I)<=cost_max)        \n",
    "m9.setObjective(gp.quicksum(e_NPV[i]*x[i][2]*mask_array[i] for i in I), GRB.MAXIMIZE)\n",
    "m9.optimize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w6/qlqct9bn2_b5pskgsph3f7hh0000gn/T/ipykernel_15356/1249264601.py:27: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  solution_gdf.to_file('solution_EnerconOnly.shp')\n"
     ]
    }
   ],
   "source": [
    "#append model results (location of turbines) to coordinates\n",
    "\n",
    "solution_df=df_expanded_sum.copy()\n",
    "vars=m9.getVars()\n",
    "Vestas_Location=np.array([])\n",
    "Nordex_Location=np.array([])\n",
    "Enercon_Location=np.array([])\n",
    "SolarPV_Location=np.array([])\n",
    "for v in range(m9.NumVars):\n",
    "    if v % 4 == 0:\n",
    "        Vestas_Location=np.append(Vestas_Location,vars[v].x)\n",
    "    else:\n",
    "        if v % 4 == 1:\n",
    "            Nordex_Location=np.append(Nordex_Location,vars[v].x)\n",
    "        else:\n",
    "            if v % 4 == 2:\n",
    "                Enercon_Location=np.append(Enercon_Location,vars[v].x)\n",
    "            else:\n",
    "                SolarPV_Location=np.append(SolarPV_Location,vars[v].x)\n",
    "            \n",
    "solution_df['Vestas_Location']=pd.Series(Vestas_Location)\n",
    "solution_df['Nordex_Location']=pd.Series(Nordex_Location)\n",
    "solution_df['Enercon_Location']=pd.Series(Enercon_Location)\n",
    "solution_df['SolarPV_Location']=pd.Series(SolarPV_Location)\n",
    "solution_df=solution_df.loc[(solution_df['Vestas_Location'] != -0) | (solution_df['Nordex_Location'] != -0) | (solution_df['Enercon_Location'] != 0) | (solution_df['SolarPV_Location'] != 0)]\n",
    "solution_gdf=geopandas.GeoDataFrame(solution_df, geometry='geometry')\n",
    "solution_gdf.to_file('solution_EnerconOnly.shp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env2",
   "language": "python",
   "name": "geo_env2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
